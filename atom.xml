<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Eureka&#39;s World</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2023-05-27T02:36:15.816Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Eureka Cheng</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>煤炭价格预测</title>
    <link href="http://example.com/2023/05/22/%E7%85%A4%E7%82%AD%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8B/"/>
    <id>http://example.com/2023/05/22/%E7%85%A4%E7%82%AD%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8B/</id>
    <published>2023-05-22T03:46:46.000Z</published>
    <updated>2023-05-27T02:36:15.816Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>煤炭属于大宗商品，煤炭价格既受国家相关部门的监管，又受国内煤炭市场的影响。除此之外，气候变化、出行方式、能源消耗方式、国际煤炭市场等其他因素也会影响煤炭价格。请完成如下问题。</p><ol><li><p>请建立数学模型，通过量化分析的方法，给出影响煤炭价格的主要因素（不超过10种），并且以秦皇岛港动力煤价格为例，给出从2019年5月1日至2020年4月30日，影响秦皇岛港动力煤价格的主要因素的排序（按影响程度从大到小排序，不超过10种）。</p></li><li><p>请结合秦皇岛港动力煤价格的历史数据(附件3)，以及问题1中的影响煤炭价格的主要因素，建立煤炭价格预测模型，分别以天、周、月为单位，预测未来31天、35周、36个月的煤炭价格，并完成表1。</p></li><li><p>为了更加准确地预测秦皇岛港动力煤价格，请综合考虑未来各种情况（例如突发事件）引起的煤炭价格影响因素在结构性和重要性方面的变化，建立煤炭价格综合预测模型，并给出模型的预测结果。</p></li></ol><p>注：</p><p>(1)附件1-秦皇岛港动力煤价格数据由“中国煤炭市场网”提供(<a href="https://www.cctd.com.cn/)%EF%BC%8C%E6%95%B0%E6%8D%AE%E6%98%AF%E4%BB%A5%E2%80%9C%E5%91%A8%E2%80%9D%E4%B8%BA%E5%8D%95%E4%BD%8D%E7%9A%84%E6%95%B0%E6%8D%AE%EF%BC%8C%E7%9B%B8%E5%85%B3%E7%9A%84%E7%85%A4%E7%82%AD%E4%BB%B7%E6%A0%BC%E6%98%AF%E6%97%A5%E6%9C%9F%E6%89%80%E5%9C%A8%E5%91%A8%E7%9A%84%E4%BB%B7%E6%A0%BC%E3%80%82">https://www.cctd.com.cn/)，数据是以“周”为单位的数据，相关的煤炭价格是日期所在周的价格。</a></p><p>(2)本题中相关参数说明如下：秦皇岛港动力煤：硫份0.8%，发热量5500kacl&#x2F;kg；</p><p>煤炭价格类型：煤炭平仓价(FOB价格，是指煤运到港口并装到船上的价格)；</p><p>煤炭价格单位：元&#x2F;吨。</p><h2 id="影响因素量化分析"><a href="#影响因素量化分析" class="headerlink" title="影响因素量化分析"></a>影响因素量化分析</h2><p>可选方案：PCA、AHP、多元线性回归</p><p><a href="https://cloud.tencent.com/developer/article/1816448">AHP使用介绍</a></p><p>层次分析法（Analytic Hierarchy Process，简称 AHP），最早是由美国运筹学家 T. L. Saaty 教授于上世纪 70 年代初期提出的一种决策方法。它的出现为我们处理决策类问题提供了一种新的思路。</p><p>在解决评价类问题时，我们通常采用的做法是对问题进行定量分析来对不同的方案做出不同的评价或是赋予不同的权重。</p><p>但当我们面对一些受主观因素影响的问题，如选择旅游目的地时，旅游地的景色、旅途、居住、饮食等都会影响着最终方案的选择。这些都受个人因素影响，而且往往缺少定量数据很难进行定量分析，这时我们就可以采用<strong>一种介于定性和定量之间分析的方法——层次分析法</strong>。</p><p>选取国际煤炭价格、煤炭产量、煤炭消费量、流通费用、替代能源占比、天气(用电量)、国民经济消费价格指数作为影响煤炭价格的7个指标。</p><p>准则层：</p><table><thead><tr><th align="center">煤炭价格预测</th><th align="center">煤炭消费量</th><th align="center">流通费用</th><th align="center">煤炭产量</th><th align="center">国际煤炭价格</th><th align="center">天气</th><th align="center">替代能源占比</th><th align="center">国民经济消费价格指数</th></tr></thead><tbody><tr><td align="center">煤炭消费量</td><td align="center">1</td><td align="center">1</td><td align="center">2</td><td align="center">2</td><td align="center">3</td><td align="center">3</td><td align="center">4</td></tr><tr><td align="center">流通费用</td><td align="center">1</td><td align="center">1</td><td align="center">2</td><td align="center">2</td><td align="center">3</td><td align="center">3</td><td align="center">4</td></tr><tr><td align="center">煤炭产量</td><td align="center">1&#x2F;2</td><td align="center">1&#x2F;2</td><td align="center">1</td><td align="center">1</td><td align="center">2</td><td align="center">2</td><td align="center">3</td></tr><tr><td align="center">国际煤炭价格</td><td align="center">1&#x2F;2</td><td align="center">1&#x2F;2</td><td align="center">1</td><td align="center">1</td><td align="center">2</td><td align="center">2</td><td align="center">3</td></tr><tr><td align="center">天气</td><td align="center">1&#x2F;3</td><td align="center">1&#x2F;3</td><td align="center">1&#x2F;2</td><td align="center">1&#x2F;2</td><td align="center">1</td><td align="center">1</td><td align="center">2</td></tr><tr><td align="center">替代能源占比</td><td align="center">1&#x2F;3</td><td align="center">1&#x2F;3</td><td align="center">1&#x2F;2</td><td align="center">1&#x2F;2</td><td align="center">1</td><td align="center">1</td><td align="center">2</td></tr><tr><td align="center">国民经济消费价格指数</td><td align="center">1&#x2F;4</td><td align="center">1&#x2F;4</td><td align="center">1&#x2F;3</td><td align="center">1&#x2F;3</td><td align="center">1&#x2F;2</td><td align="center">1&#x2F;2</td><td align="center">1</td></tr></tbody></table><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">clc,clear</span><br><span class="line"><span class="comment">%准则层判断矩阵</span></span><br><span class="line">z=[<span class="number">1</span> <span class="number">1</span> <span class="number">2</span> <span class="number">2</span> <span class="number">3</span> <span class="number">3</span> <span class="number">4</span>;</span><br><span class="line">   <span class="number">1</span> <span class="number">1</span> <span class="number">2</span> <span class="number">2</span> <span class="number">3</span> <span class="number">3</span> <span class="number">4</span>;</span><br><span class="line">   <span class="number">1</span>/<span class="number">2</span> <span class="number">1</span>/<span class="number">2</span> <span class="number">1</span> <span class="number">1</span> <span class="number">2</span> <span class="number">2</span> <span class="number">3</span>;</span><br><span class="line">   <span class="number">1</span>/<span class="number">2</span> <span class="number">1</span>/<span class="number">2</span> <span class="number">1</span> <span class="number">1</span> <span class="number">2</span> <span class="number">2</span> <span class="number">3</span>;</span><br><span class="line">   <span class="number">1</span>/<span class="number">3</span> <span class="number">1</span>/<span class="number">3</span> <span class="number">1</span>/<span class="number">2</span> <span class="number">1</span>/<span class="number">2</span> <span class="number">1</span> <span class="number">1</span> <span class="number">2</span>;</span><br><span class="line">   <span class="number">1</span>/<span class="number">3</span> <span class="number">1</span>/<span class="number">3</span> <span class="number">1</span>/<span class="number">2</span> <span class="number">1</span>/<span class="number">2</span> <span class="number">1</span> <span class="number">1</span> <span class="number">2</span>;</span><br><span class="line">   <span class="number">1</span>/<span class="number">4</span> <span class="number">1</span>/<span class="number">4</span> <span class="number">1</span>/<span class="number">3</span> <span class="number">1</span>/<span class="number">3</span> <span class="number">1</span>/<span class="number">2</span> <span class="number">1</span>/<span class="number">2</span> <span class="number">1</span>];</span><br><span class="line">r=[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.58</span>,<span class="number">0.90</span>,<span class="number">1.12</span>,<span class="number">1.24</span>,<span class="number">1.32</span>,<span class="number">1.41</span>,<span class="number">1.45</span>]; <span class="comment">%一致性指标</span></span><br><span class="line">n1=<span class="number">7</span>;</span><br><span class="line">[x,y]=eig(z);</span><br><span class="line">lamda=<span class="built_in">max</span>(<span class="built_in">diag</span>(y));</span><br><span class="line">num=<span class="built_in">find</span>(<span class="built_in">diag</span>(y)==lamda);</span><br><span class="line">zw=x(:,num)/sum(x(:,num));</span><br><span class="line"><span class="built_in">disp</span>(<span class="string">&#x27;层次单排序检验指标为：&#x27;</span>)</span><br><span class="line">cr1=((lamda<span class="number">-7</span>)/(n1<span class="number">-1</span>))/r(n1)<span class="comment">%层次单排序准则层一致性检验指标</span></span><br><span class="line"><span class="keyword">if</span> cr1&gt;<span class="number">0.1</span></span><br><span class="line">    error(<span class="string">&quot;一致性检验不通过&quot;</span>)</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">disp</span>(<span class="string">&#x27;准则层权值:&#x27;</span>)</span><br><span class="line">zww = zw&#x27;</span><br><span class="line"></span><br><span class="line">-------------------------------------------------------------------------------</span><br><span class="line">运行结果：</span><br><span class="line">层次单排序检验指标为：</span><br><span class="line"></span><br><span class="line">cr1 =</span><br><span class="line"></span><br><span class="line">    <span class="number">0.0060</span></span><br><span class="line"></span><br><span class="line">准则层权值:</span><br><span class="line"></span><br><span class="line">zww =</span><br><span class="line"></span><br><span class="line">    <span class="number">0.2501</span>    <span class="number">0.2501</span>    <span class="number">0.1437</span>    <span class="number">0.1437</span>    <span class="number">0.0813</span>    <span class="number">0.0813</span>    <span class="number">0.0500</span></span><br></pre></td></tr></table></figure><h2 id="初步预测模型建立"><a href="#初步预测模型建立" class="headerlink" title="初步预测模型建立"></a>初步预测模型建立</h2><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">clc;</span><br><span class="line">clear;</span><br><span class="line"></span><br><span class="line"><span class="comment">% 读取文件</span></span><br><span class="line">filename = <span class="string">&#x27;G:\workhome\临时空间\price.xlsx&#x27;</span>;</span><br><span class="line">data = readmatrix(filename);</span><br><span class="line"></span><br><span class="line"><span class="comment">% 提取价格特征数据</span></span><br><span class="line">priceFeatures = data(:, <span class="number">2</span>:<span class="keyword">end</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% 数据归一化</span></span><br><span class="line">normalized_features = normalize(priceFeatures);</span><br><span class="line"></span><br><span class="line"><span class="comment">% 划分训练集和测试集</span></span><br><span class="line">split_ratio = <span class="number">0.8</span>;  <span class="comment">% 训练集和测试集的比例</span></span><br><span class="line">split_index = <span class="built_in">round</span>(split_ratio * <span class="built_in">size</span>(normalized_features, <span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">train_data = normalized_features(<span class="number">1</span>:split_index<span class="number">-1</span>, :);</span><br><span class="line">train_target = normalized_features(<span class="number">2</span>:split_index, :);</span><br><span class="line"></span><br><span class="line">test_data = normalized_features(split_index:<span class="keyword">end</span><span class="number">-1</span>, :);</span><br><span class="line">test_target = normalized_features(split_index+<span class="number">1</span>:<span class="keyword">end</span>, :);</span><br><span class="line"></span><br><span class="line"><span class="comment">% 将数据调整为每个时间步只有一个特征</span></span><br><span class="line">train_data = train_data(:, <span class="number">1</span>);</span><br><span class="line">train_target = train_target(:, <span class="number">1</span>);</span><br><span class="line">test_data = test_data(:, <span class="number">1</span>);</span><br><span class="line">test_target = test_target(:, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% 将数据调整为正确的形状</span></span><br><span class="line">train_data = train_data&#x27;;</span><br><span class="line">train_target = train_target&#x27;;</span><br><span class="line">test_data = test_data&#x27;;</span><br><span class="line">test_target = test_target&#x27;;</span><br><span class="line"></span><br><span class="line"><span class="comment">% 步骤2：构建LSTM模型</span></span><br><span class="line">numHiddenUnits = <span class="number">200</span>;  <span class="comment">% LSTM隐藏单元数</span></span><br><span class="line">numFeatures = <span class="number">1</span>;  <span class="comment">% 输入特征数为1</span></span><br><span class="line"></span><br><span class="line">layers = [ ...</span><br><span class="line">    sequenceInputLayer(numFeatures)</span><br><span class="line">    lstmLayer(numHiddenUnits)</span><br><span class="line">    fullyConnectedLayer(<span class="number">1</span>)  <span class="comment">% 输出层只有一个节点</span></span><br><span class="line">    regressionLayer];</span><br><span class="line"></span><br><span class="line"><span class="comment">% 步骤3：训练LSTM模型</span></span><br><span class="line">maxEpochs = <span class="number">100</span>;  <span class="comment">% 最大迭代次数</span></span><br><span class="line">miniBatchSize = <span class="number">32</span>;  <span class="comment">% mini-batch大小</span></span><br><span class="line"></span><br><span class="line">options = trainingOptions(<span class="string">&#x27;adam&#x27;</span>, ...</span><br><span class="line">    <span class="string">&#x27;MaxEpochs&#x27;</span>, maxEpochs, ...</span><br><span class="line">    <span class="string">&#x27;MiniBatchSize&#x27;</span>, miniBatchSize, ...</span><br><span class="line">    <span class="string">&#x27;GradientThreshold&#x27;</span>, <span class="number">1</span>, ...</span><br><span class="line">    <span class="string">&#x27;Shuffle&#x27;</span>, <span class="string">&#x27;every-epoch&#x27;</span>, ...</span><br><span class="line">    <span class="string">&#x27;Verbose&#x27;</span>, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">net = trainNetwork(train_data, train_target, layers, options);</span><br><span class="line"></span><br><span class="line"><span class="comment">% 步骤4：使用训练好的LSTM模型进行预测</span></span><br><span class="line"><span class="comment">% 预测未来31个时间步的价格</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 使用测试集的最后一个时间步的数据进行预测</span></span><br><span class="line">initialInput = test_data(:, <span class="keyword">end</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% 预测未来31个时间步的价格</span></span><br><span class="line">numTimeSteps = <span class="number">31</span>;</span><br><span class="line">predictedPrices = <span class="built_in">zeros</span>(<span class="number">1</span>, numTimeSteps);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:numTimeSteps</span><br><span class="line">    <span class="comment">% 对输入进行预测</span></span><br><span class="line">    nextPrice = predict(net, initialInput);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">% 更新输入</span></span><br><span class="line">    initialInput = nextPrice;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">% 保存预测结果</span></span><br><span class="line">    predictedPrices(<span class="built_in">i</span>) = nextPrice;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 步骤5：可视化预测结果</span></span><br><span class="line">actualPrices = data(:, <span class="number">2</span>)&#x27;;</span><br><span class="line"><span class="built_in">figure</span>;</span><br><span class="line"><span class="built_in">plot</span>(actualPrices, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;LineWidth&#x27;</span>, <span class="number">1.5</span>);</span><br><span class="line"><span class="built_in">hold</span> on;</span><br><span class="line"><span class="built_in">plot</span>(<span class="built_in">length</span>(actualPrices)+<span class="number">1</span>:<span class="built_in">length</span>(actualPrices)+numTimeSteps, predictedPrices, <span class="string">&#x27;r--&#x27;</span>, <span class="string">&#x27;LineWidth&#x27;</span>, <span class="number">1.5</span>);</span><br><span class="line">xlabel(<span class="string">&#x27;时间&#x27;</span>);</span><br><span class="line">ylabel(<span class="string">&#x27;价格&#x27;</span>);</span><br><span class="line"><span class="built_in">legend</span>(<span class="string">&#x27;实际价格&#x27;</span>, <span class="string">&#x27;预测价格&#x27;</span>);</span><br><span class="line">title(<span class="string">&#x27;煤炭价格预测&#x27;</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">%% 预测未来煤炭价格(闭环预测)</span><br><span class="line">% 初始化RNN状态</span><br><span class="line">net = resetState(net);</span><br><span class="line">offset = size(P_train,2);</span><br><span class="line">[net,Z] = predictAndUpdateState(net,p_train);</span><br><span class="line"></span><br><span class="line">% 预测未来31天煤炭价格</span><br><span class="line">numPredictionTimeSteps = 31;</span><br><span class="line">Xt = Z(:,end);</span><br><span class="line">Y = zeros(1,numPredictionTimeSteps);</span><br><span class="line"></span><br><span class="line">for t = 1:numPredictionTimeSteps</span><br><span class="line">    [net,Y(:,t)] = predictAndUpdateState(net,Xt);</span><br><span class="line">    Xt = Y(:,t);</span><br><span class="line">end</span><br><span class="line">%预测结果可视化</span><br><span class="line">numTimeSteps = offset + numPredictionTimeSteps;</span><br><span class="line">numChannels = 1;</span><br><span class="line"></span><br><span class="line">figure</span><br><span class="line">t = tiledlayout(1,1);</span><br><span class="line">title(t,&quot;闭环预测&quot;)</span><br><span class="line">for i = 1:numChannels</span><br><span class="line">    nexttile</span><br><span class="line">    plot(T(i,1:offset))</span><br><span class="line">    hold on</span><br><span class="line">    plot(offset:numTimeSteps,[T(i,offset) Y(i,:)],&#x27;--&#x27;)</span><br><span class="line">    ylabel(&quot;Channel &quot; + i)</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">xlabel(&quot;Time Step&quot;)</span><br><span class="line">nexttile(1)</span><br><span class="line">legend([&quot;Input&quot; &quot;Forecasted&quot;])</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">%% 计算残差</span><br><span class="line">residuals_train = T_sim1&#x27; - T_train;</span><br><span class="line">residuals_test = T_sim2&#x27; - T_test;</span><br><span class="line"></span><br><span class="line">%% 残差分析可视化</span><br><span class="line">figure</span><br><span class="line">subplot(2, 1, 1)</span><br><span class="line">scatter(1:M, residuals_train)</span><br><span class="line">xlabel(&#x27;训练样本&#x27;)</span><br><span class="line">ylabel(&#x27;残差&#x27;)</span><br><span class="line">title(&#x27;训练集残差分析&#x27;)</span><br><span class="line"></span><br><span class="line">subplot(2, 1, 2)</span><br><span class="line">scatter(1:N, residuals_test)</span><br><span class="line">xlabel(&#x27;测试样本&#x27;)</span><br><span class="line">ylabel(&#x27;残差&#x27;)</span><br><span class="line">title(&#x27;测试集残差分析&#x27;)</span><br><span class="line"></span><br><span class="line">%% 残差直方图</span><br><span class="line">figure</span><br><span class="line">subplot(2, 1, 1)</span><br><span class="line">histogram(residuals_train)</span><br><span class="line">xlabel(&#x27;残差&#x27;)</span><br><span class="line">ylabel(&#x27;频数&#x27;)</span><br><span class="line">title(&#x27;训练集残差直方图&#x27;)</span><br><span class="line"></span><br><span class="line">subplot(2, 1, 2)</span><br><span class="line">histogram(residuals_test)</span><br><span class="line">xlabel(&#x27;残差&#x27;)</span><br><span class="line">ylabel(&#x27;频数&#x27;)</span><br><span class="line">title(&#x27;测试集残差直方图&#x27;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">%% 相关性评估</span><br><span class="line">correlation_train = corr(T_sim1, T_train&#x27;);</span><br><span class="line">correlation_test = corr(T_sim2, T_test&#x27;);</span><br><span class="line"></span><br><span class="line">disp([&#x27;训练集预测结果与真实值的相关性：&#x27;, num2str(correlation_train)]);</span><br><span class="line">disp([&#x27;测试集预测结果与真实值的相关性：&#x27;, num2str(correlation_test)]);</span><br><span class="line"></span><br><span class="line">%% 真实值与预测值的散点图</span><br><span class="line">figure</span><br><span class="line">subplot(2, 1, 1)</span><br><span class="line">scatter(T_train, T_sim1)</span><br><span class="line">hold on</span><br><span class="line">line([min(T_train), max(T_train)], [min(T_train), max(T_train)], &#x27;Color&#x27;, &#x27;red&#x27;, &#x27;LineWidth&#x27;, 1)</span><br><span class="line">hold off</span><br><span class="line">xlabel(&#x27;真实值&#x27;)</span><br><span class="line">ylabel(&#x27;预测值&#x27;)</span><br><span class="line">title(&#x27;训练集真实值与预测值的关系&#x27;)</span><br><span class="line">legend(&#x27;数据&#x27;, &#x27;相关性为1&#x27;, &#x27;Location&#x27;, &#x27;northwest&#x27;)</span><br><span class="line"></span><br><span class="line">subplot(2, 1, 2)</span><br><span class="line">scatter(T_test, T_sim2)</span><br><span class="line">hold on</span><br><span class="line">line([min(T_test), max(T_test)], [min(T_test), max(T_test)], &#x27;Color&#x27;, &#x27;red&#x27;, &#x27;LineWidth&#x27;, 1)</span><br><span class="line">hold off</span><br><span class="line">xlabel(&#x27;真实值&#x27;)</span><br><span class="line">ylabel(&#x27;预测值&#x27;)</span><br><span class="line">title(&#x27;测试集真实值与预测值的关系&#x27;)</span><br><span class="line">legend(&#x27;数据&#x27;, &#x27;相关性为1&#x27;, &#x27;Location&#x27;, &#x27;northwest&#x27;)</span><br></pre></td></tr></table></figure><p>残差的范围并不能直接用于判定模型的好坏，而应该综合考虑其他因素。残差的分布和特征可以提供有关模型性能的一些信息，但不能作为唯一的评估指标。</p><p>一般来说，一个好的模型应该具备以下性质：</p><ol><li><p>残差的平均值接近于零：好的模型应该能够捕捉到数据中的整体趋势，使得预测结果与真实值的平均差异接近于零。</p></li><li><p>残差的方差稳定：好的模型应该使残差的方差相对较小，即预测值与真实值之间的差异相对较小，表示模型的预测能力较强。</p></li><li><p>残差的分布应接近正态分布：好的模型应该使残差的分布接近正态分布，即大部分的残差值集中在零附近，而不是出现明显的偏斜或离群值。</p></li><li><p>残差之间应该不存在明显的相关性：好的模型应该能够捕捉到数据中的所有相关信息，并将其纳入预测中，从而减少残差之间的相关性。</p></li></ol><p>因此，对于残差的判断并没有一个固定的范围，而是需要综合考虑以上几个因素，并与其他模型进行比较。此外，模型的好坏还应该考虑其他评估指标，如预测准确性、泛化能力等。因此，建议结合多个评估指标和可视化结果，综合评估模型的好坏。</p><h2 id="综合预测模型建立"><a href="#综合预测模型建立" class="headerlink" title="综合预测模型建立"></a>综合预测模型建立</h2><p>AHP考虑疫情，提出方案层，求出新的影响因素对应权重，改良预测神经网络，重新预测。</p><p>煤炭消费量、流通费用、煤炭产量、国际煤炭价格、天气、替代能源占比、国民经济消费价格指数</p><p>突发事件：、全球疫情、煤矿安全事故、金融危机</p><p>依据发生的或者有可能发生的突发事件对煤炭价格带来的影响，提出能进一步预测煤炭价格的三个可能方案：</p><p>（&#x3D;&#x3D;影响依次递减&#x3D;&#x3D;）</p><p>方案一：流通费用、国民经济消费价格指数、国际煤炭价格、替代能源占比、煤炭消费量、煤炭产量、天气</p><p>方案二：煤炭产量、流通费用、国际煤炭价格、国民经济消费指数、煤炭消费量、替代能源占比、天气</p><p>方案三：煤炭消费量、流通费用、煤炭产量、国际煤炭价格、天气、替代能源占比、国民经济消费价格指数</p><table><thead><tr><th>煤炭消费量</th><th>方案一</th><th>方案二</th><th align="center">方案三</th><th>流通费用</th><th>方案一</th><th>方案二</th><th>方案三</th><th>煤炭产量</th><th>方案一</th><th>方案二</th><th>方案三</th></tr></thead><tbody><tr><td>方案一</td><td>1</td><td>1</td><td align="center">3&#x2F;7</td><td>方案一</td><td>1</td><td>7&#x2F;6</td><td>7&#x2F;6</td><td>方案一</td><td>1</td><td>2&#x2F;7</td><td>1&#x2F;2</td></tr><tr><td>方案二</td><td>1</td><td>1</td><td align="center">3&#x2F;7</td><td>方案二</td><td>6&#x2F;7</td><td>1</td><td>1</td><td>方案二</td><td>7&#x2F;2</td><td>1</td><td>7&#x2F;4</td></tr><tr><td>方案三</td><td>7&#x2F;3</td><td>7&#x2F;3</td><td align="center">1</td><td>方案三</td><td>6&#x2F;7</td><td>1</td><td>1</td><td>方案三</td><td>2</td><td>4&#x2F;7</td><td>1</td></tr><tr><td>国际煤炭价格</td><td>方案一</td><td>方案二</td><td align="center">方案三</td><td>天气</td><td>方案一</td><td>方案二</td><td>方案三</td><td>替代能源占比</td><td>方案一</td><td>方案二</td><td>方案三</td></tr><tr><td>方案一</td><td>1</td><td>1</td><td align="center">4&#x2F;3</td><td>方案一</td><td>1</td><td>1</td><td>1&#x2F;3</td><td>方案一</td><td>1</td><td>2</td><td>2</td></tr><tr><td>方案二</td><td>1</td><td>1</td><td align="center">1</td><td>方案二</td><td>1</td><td>1</td><td>1&#x2F;3</td><td>方案二</td><td>1&#x2F;2</td><td>1</td><td>1</td></tr><tr><td>方案三</td><td>3&#x2F;4</td><td>1</td><td align="center">1</td><td>方案三</td><td>3</td><td>3</td><td>1</td><td>方案三</td><td>1&#x2F;2</td><td>1</td><td>1</td></tr></tbody></table><table><thead><tr><th align="center">国民经济消费价格指数</th><th>方案一</th><th>方案二</th><th>方案三</th></tr></thead><tbody><tr><td align="center">方案一</td><td>1</td><td>3&#x2F;2</td><td>6</td></tr><tr><td align="center">方案二</td><td>2&#x2F;3</td><td>1</td><td>4</td></tr><tr><td align="center">方案三</td><td>1&#x2F;6</td><td>1&#x2F;4</td><td>1</td></tr></tbody></table><h2 id="期间知识总结"><a href="#期间知识总结" class="headerlink" title="期间知识总结"></a>期间知识总结</h2><h3 id="matlab元胞"><a href="#matlab元胞" class="headerlink" title="matlab元胞:"></a>matlab元胞:</h3><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="comment">% 创建一个包含不同类型数据的数据元胞</span></span><br><span class="line">C = &#123;<span class="number">1</span>, <span class="string">&#x27;hello&#x27;</span>, [<span class="number">2</span> <span class="number">3</span> <span class="number">4</span>], struct(<span class="string">&#x27;field&#x27;</span>, <span class="string">&#x27;value&#x27;</span>)&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">% 访问和修改数据元胞中的元素</span></span><br><span class="line">C&#123;<span class="number">1</span>&#125; = <span class="number">10</span>;  <span class="comment">% 将第一个元胞的值修改为 10</span></span><br><span class="line">str = C&#123;<span class="number">2</span>&#125;; <span class="comment">% 从第二个元胞中提取字符串</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 使用 cellfun 对数据元胞中的每个元素应用函数</span></span><br><span class="line">newC = <span class="built_in">cellfun</span>(@<span class="built_in">sqrt</span>, C); <span class="comment">% 对每个元胞的数值类型元素应用平方根函数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 使用 cell2mat 将数据元胞中的数值类型元素合并为一个矩阵</span></span><br><span class="line">M = cell2mat(C(<span class="number">1</span>:<span class="number">3</span>)); <span class="comment">% 将前三个元胞的数值类型元素合并为一个矩阵</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 使用 cell2struct 将数据元胞中的元素转换为结构体</span></span><br><span class="line">fieldnames = &#123;<span class="string">&#x27;number&#x27;</span>, <span class="string">&#x27;text&#x27;</span>, <span class="string">&#x27;matrix&#x27;</span>, <span class="string">&#x27;struct&#x27;</span>&#125;;</span><br><span class="line">S = cell2struct(C, fieldnames); <span class="comment">% 将数据元胞中的元素转换为结构体，指定字段名</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 显示结果</span></span><br><span class="line"><span class="built_in">disp</span>(C);</span><br><span class="line"><span class="built_in">disp</span>(newC);</span><br><span class="line"><span class="built_in">disp</span>(M);</span><br><span class="line"><span class="built_in">disp</span>(S);</span><br><span class="line">-------------------------------------------------------------------------------------</span><br><span class="line">C =</span><br><span class="line">  <span class="number">10</span></span><br><span class="line">  <span class="string">&#x27;hello&#x27;</span></span><br><span class="line">  [<span class="number">1</span>x3 double]</span><br><span class="line">  <span class="number">1</span>x1 struct array with fields:</span><br><span class="line">    field</span><br><span class="line"></span><br><span class="line">newC =</span><br><span class="line">  <span class="number">3.1623</span></span><br><span class="line">     NaN</span><br><span class="line">     NaN</span><br><span class="line">     NaN</span><br><span class="line"></span><br><span class="line">M =</span><br><span class="line">     <span class="number">10</span></span><br><span class="line">    NaN</span><br><span class="line">      <span class="number">2</span></span><br><span class="line">      <span class="number">3</span></span><br><span class="line">      <span class="number">4</span></span><br><span class="line"></span><br><span class="line">S = </span><br><span class="line">  struct with fields:</span><br><span class="line">    number: <span class="number">10</span></span><br><span class="line">      text: <span class="string">&#x27;hello&#x27;</span></span><br><span class="line">    matrix: [<span class="number">2</span> <span class="number">3</span> <span class="number">4</span>]</span><br><span class="line">    struct: [<span class="number">1</span>x1 struct]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="数据保存到excle文件中"><a href="#数据保存到excle文件中" class="headerlink" title="数据保存到excle文件中"></a>数据保存到excle文件中</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt; xlsname = &#x27;predictions.xlsx&#x27;;</span><br><span class="line">&gt;&gt; sheetname = &#x27;Sheet1&#x27;;</span><br><span class="line">&gt;&gt; xlswrite(xlsname, predicted_data, sheetname);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data1 = [1; 2; 3];  % 要写入第一列的数据</span><br><span class="line">data2 = [4; 5; 6];  % 要写入第二列的数据</span><br><span class="line">data3 = [7; 8; 9];  % 要写入第三列的数据</span><br><span class="line"></span><br><span class="line">filename = &#x27;output.xlsx&#x27;;  % Excel 文件名</span><br><span class="line">sheet = &#x27;Sheet1&#x27;;  % 要写入的工作表名称</span><br><span class="line">startRange = &#x27;A1&#x27;;  % 数据写入的起始位置</span><br><span class="line"></span><br><span class="line">xlswrite(filename, data1, sheet, startRange);  % 将数据1写入 Excel 文件的指定工作表的指定位置</span><br><span class="line">xlswrite(filename, data2, sheet, &#x27;B1&#x27;);  % 将数据2写入 Excel 文件的指定工作表的指定位置</span><br><span class="line">xlswrite(filename, data3, sheet, &#x27;C1&#x27;);  % 将数据3写入 Excel 文件的指定工作表的指定位置</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="保存模型"><a href="#保存模型" class="headerlink" title="保存模型"></a>保存模型</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">save(&#x27;model.mat&#x27;, &#x27;net&#x27;)</span><br><span class="line">load model.mat</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;问题描述&quot;&gt;&lt;a href=&quot;#问题描述&quot; class=&quot;headerlink&quot; title=&quot;问题描述&quot;&gt;&lt;/a&gt;问题描述&lt;/h2&gt;&lt;p&gt;煤炭属于大宗商品，煤炭价格既受国家相关部门的监管，又受国内煤炭市场的影响。除此之外，气候变化、出行方式、能源消耗方式、国际煤</summary>
      
    
    
    
    <category term="数学建模" scheme="http://example.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"/>
    
    
    <category term="时间序列预测" scheme="http://example.com/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>实用工具</title>
    <link href="http://example.com/2023/04/09/%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7/"/>
    <id>http://example.com/2023/04/09/%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7/</id>
    <published>2023-04-09T13:28:43.000Z</published>
    <updated>2023-04-09T13:30:45.115Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.win11app.com/balabolka-for-pc.html">Balabolka下载地址</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://www.win11app.com/balabolka-for-pc.html&quot;&gt;Balabolka下载地址&lt;/a&gt;&lt;/p&gt;
</summary>
      
    
    
    
    <category term="工具合集" scheme="http://example.com/categories/%E5%B7%A5%E5%85%B7%E5%90%88%E9%9B%86/"/>
    
    
    <category term="实用工具" scheme="http://example.com/tags/%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>CycleGAN预训练</title>
    <link href="http://example.com/2023/03/30/CycleGAN%E9%A2%84%E8%AE%AD%E7%BB%83/"/>
    <id>http://example.com/2023/03/30/CycleGAN%E9%A2%84%E8%AE%AD%E7%BB%83/</id>
    <published>2023-03-30T08:45:23.000Z</published>
    <updated>2023-03-30T09:03:07.177Z</updated>
    
    <content type="html"><![CDATA[<p><em><strong>由.ipynb文件转化而成</strong></em></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResNetBlock</span>(nn.Module): </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(ResNetBlock, self).__init__()</span><br><span class="line">        self.conv_block = self.build_conv_block(dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">build_conv_block</span>(<span class="params">self, dim</span>):</span><br><span class="line">        conv_block = []</span><br><span class="line"></span><br><span class="line">        conv_block += [nn.ReflectionPad2d(<span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">        conv_block += [nn.Conv2d(dim, dim, kernel_size=<span class="number">3</span>, padding=<span class="number">0</span>, bias=<span class="literal">True</span>),</span><br><span class="line">                       nn.InstanceNorm2d(dim),</span><br><span class="line">                       nn.ReLU(<span class="literal">True</span>)]</span><br><span class="line"></span><br><span class="line">        conv_block += [nn.ReflectionPad2d(<span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">        conv_block += [nn.Conv2d(dim, dim, kernel_size=<span class="number">3</span>, padding=<span class="number">0</span>, bias=<span class="literal">True</span>),</span><br><span class="line">                       nn.InstanceNorm2d(dim)]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*conv_block)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = x + self.conv_block(x) </span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResNetGenerator</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_nc=<span class="number">3</span>, output_nc=<span class="number">3</span>, ngf=<span class="number">64</span>, n_blocks=<span class="number">9</span></span>): </span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span>(n_blocks &gt;= <span class="number">0</span>)</span><br><span class="line">        <span class="built_in">super</span>(ResNetGenerator, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.input_nc = input_nc</span><br><span class="line">        self.output_nc = output_nc</span><br><span class="line">        self.ngf = ngf</span><br><span class="line"></span><br><span class="line">        model = [nn.ReflectionPad2d(<span class="number">3</span>),</span><br><span class="line">                 nn.Conv2d(input_nc, ngf, kernel_size=<span class="number">7</span>, padding=<span class="number">0</span>, bias=<span class="literal">True</span>),</span><br><span class="line">                 nn.InstanceNorm2d(ngf),</span><br><span class="line">                 nn.ReLU(<span class="literal">True</span>)]</span><br><span class="line"></span><br><span class="line">        n_downsampling = <span class="number">2</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_downsampling):</span><br><span class="line">            mult = <span class="number">2</span>**i</span><br><span class="line">            model += [nn.Conv2d(ngf * mult, ngf * mult * <span class="number">2</span>, kernel_size=<span class="number">3</span>,</span><br><span class="line">                                stride=<span class="number">2</span>, padding=<span class="number">1</span>, bias=<span class="literal">True</span>),</span><br><span class="line">                      nn.InstanceNorm2d(ngf * mult * <span class="number">2</span>),</span><br><span class="line">                      nn.ReLU(<span class="literal">True</span>)]</span><br><span class="line"></span><br><span class="line">        mult = <span class="number">2</span>**n_downsampling</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_blocks):</span><br><span class="line">            model += [ResNetBlock(ngf * mult)]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_downsampling):</span><br><span class="line">            mult = <span class="number">2</span>**(n_downsampling - i)</span><br><span class="line">            model += [nn.ConvTranspose2d(ngf * mult, <span class="built_in">int</span>(ngf * mult / <span class="number">2</span>),</span><br><span class="line">                                         kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>,</span><br><span class="line">                                         padding=<span class="number">1</span>, output_padding=<span class="number">1</span>,</span><br><span class="line">                                         bias=<span class="literal">True</span>),</span><br><span class="line">                      nn.InstanceNorm2d(<span class="built_in">int</span>(ngf * mult / <span class="number">2</span>)),</span><br><span class="line">                      nn.ReLU(<span class="literal">True</span>)]</span><br><span class="line"></span><br><span class="line">        model += [nn.ReflectionPad2d(<span class="number">3</span>)]</span><br><span class="line">        model += [nn.Conv2d(ngf, output_nc, kernel_size=<span class="number">7</span>, padding=<span class="number">0</span>)]</span><br><span class="line">        model += [nn.Tanh()]</span><br><span class="line"></span><br><span class="line">        self.model = nn.Sequential(*model)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span></span>): </span><br><span class="line">        <span class="keyword">return</span> self.model(<span class="built_in">input</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">netG = ResNetGenerator()</span><br></pre></td></tr></table></figure><ol><li><strong>使用模型load_state_dict()方法将权重加载到ResNetGenerator中</strong></li><li><strong>torch.load() 是 PyTorch 库中的一个函数，用于从文件中加载序列化对象。该函数接受一个文件路径作为参数，可以加载包括张量、模型和优化器等在内的各种对象。该函数可以帮助用户在 PyTorch 中保存和加载模型、权重和其他状态信息，使得用户可以方便地在训练和测试之间共享状态信息，或在不同的设备上使用相同的模型。</strong></li></ol><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model_path = <span class="string">r&quot;G:\workspace\dlwpt-code\data\p1ch2\horse2zebra_0.4.0.pth&quot;</span></span><br><span class="line">model_data = torch.load(model_path)</span><br><span class="line">netG.load_state_dict(model_data)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;All keys matched successfully&gt;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">netG.<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ResNetGenerator(</span><br><span class="line">  (model): Sequential(</span><br><span class="line">    (0): ReflectionPad2d((3, 3, 3, 3))</span><br><span class="line">    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))</span><br><span class="line">    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)</span><br><span class="line">    (3): ReLU(inplace=True)</span><br><span class="line">    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))</span><br><span class="line">    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)</span><br><span class="line">    (6): ReLU(inplace=True)</span><br><span class="line">    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))</span><br><span class="line">    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)</span><br><span class="line">    (9): ReLU(inplace=True)</span><br><span class="line">    (10): ResNetBlock(</span><br><span class="line">      (conv_block): Sequential(</span><br><span class="line">        (0): ReflectionPad2d((1, 1, 1, 1))</span><br><span class="line">        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))</span><br><span class="line">        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)</span><br><span class="line">        (3): ReLU(inplace=True)</span><br><span class="line">        (4): ReflectionPad2d((1, 1, 1, 1))</span><br><span class="line">        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))</span><br><span class="line">        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">    )</span><br><span class="line">    (19): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))</span><br><span class="line">    (20): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)</span><br><span class="line">    (21): ReLU(inplace=True)</span><br><span class="line">    (22): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))</span><br><span class="line">    (23): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)</span><br><span class="line">    (24): ReLU(inplace=True)</span><br><span class="line">    (25): ReflectionPad2d((3, 3, 3, 3))</span><br><span class="line">    (26): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))</span><br><span class="line">    (27): Tanh()</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">preprocess = transforms.Compose([transforms.Resize(<span class="number">256</span>),</span><br><span class="line">                                 transforms.ToTensor()])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img = Image.<span class="built_in">open</span>(<span class="string">r&quot;G:\workspace\dlwpt-code\data\p1ch2\horse.jpg&quot;</span>)</span><br><span class="line">img</span><br></pre></td></tr></table></figure><img src="/2023/03/30/CycleGAN%E9%A2%84%E8%AE%AD%E7%BB%83/horse.jpg" class=""><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img_t = preprocess(img)</span><br><span class="line">batch_t = torch.unsqueeze(img_t, <span class="number">0</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">batch_out = netG(batch_t)</span><br></pre></td></tr></table></figure><p>.data 是一个属性，用于从一个张量或变量中获取其包含的数据值。通过调用 .data，可以获得一个新的张量，它与原来的张量共享存储空间，但是没有梯度信息。这个新的张量是一个<strong>纯张量</strong>，不再与计算图相关联，因此不会对梯度计算产生影响。这可以用来获得原始张量的值，同时避免在反向传播过程中计算梯度。<br>在这里，.data 被用于从 batch_out 变量或张量中提取其包含的张量数据，以便对其执行 squeeze() 和其他操作。需要注意的是，使用 .data 时需要小心，因为它会丢失与计算图相关的梯度信息，可能会对反向传播产生影响。如果您需要获取张量的值，而不是将其传递给其他 PyTorch 函数或操作，建议使用 <strong>.detach()</strong> 方法来获取一个与原始张量共享存储空间的新张量，但不共享梯度信息，从而更加安全和可靠。</p><p>squeeze() 是一个张量的方法，用于<strong>从张量中删除大小为 1 的维度</strong>。具体来说，如果张量 t 包含大小为 1 的维度，则调用 t.squeeze() 将返回一个新的张量，其中删除了所有大小为 1 的维度。如果张量中没有大小为 1 的维度，则不会进行任何更改，而是返回原始张量。如果您希望只删除特定的维度，则可以使用 t.squeeze(dim)，其中 dim 是一个整数或元组，表示要删除的维度的索引。<br><strong>例如</strong>，假设 t 是一个形状为 (1, 3, 1, 5) 的张量。调用 t.squeeze() 将返回一个形状为 (3, 5) 的张量，其中所有大小为 1 的维度都被删除。调用 t.squeeze(0) 将返回一个形状为 (3, 1, 5) 的张量，其中第一个维度（索引为 0）被删除。调用 t.squeeze((0, 2)) 将返回一个形状为 (3, 5) 的张量，其中第一个和第三个维度（索引为 0 和 2）都被删除。<br>在这里，.squeeze() 被用于从 batch_out 张量中删除大小为 1 的维度，以便进行后续的计算和操作。在神经网络的计算过程中，经常会出现大小为 1 的维度，这些维度可能是由于卷积或池化操作的结果产生的。删除这些维度可以减少张量的维度数，从而使它更容易处理和可视化。</p><p>.unsqueeze() 是一个张量的方法，用于<strong>向张量中添加大小为 1 的维度</strong>。具体来说，如果张量 t 的形状为 (n1, n2, …, nd)，则调用 t.unsqueeze(dim) 将返回一个新的张量，其形状为 (n1, n2, …, n_{dim-1}, 1, n_{dim}, …, nd)。其中，dim 表示要添加的维度的索引，从 0 开始计数。如果 dim 超过了 t 的维度，则会在最后添加新的维度。<br><strong>例如</strong>，假设 t 是一个形状为 (3, 5) 的张量。调用 t.unsqueeze(0) 将返回一个形状为 (1, 3, 5) 的张量，其中在最前面添加了一个大小为 1 的维度。调用 t.unsqueeze(1) 将返回一个形状为 (3, 1, 5) 的张量，其中在第二个维度（索引为 1）添加了一个大小为 1 的维度。调用 t.unsqueeze(2) 将返回一个形状为 (3, 5, 1) 的张量，其中在最后面添加了一个大小为 1 的维度。<br>在神经网络的计算过程中，经常需要在张量的特定维度上添加新的维度，以便进行其他计算和操作。例如，在卷积神经网络中，可以使用 .unsqueeze() 将输入张量的通道维度从 2 扩展到 3，以便将其传递给卷积层进行处理。<br>需要注意的是，在使用 .unsqueeze() 时，应该始终考虑新的维度是否对应着实际意义，以避免在后续计算中出现意外错误。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">out_t = (batch_out.data.squeeze() + <span class="number">1.0</span>) / <span class="number">2.0</span></span><br><span class="line">out_img = transforms.ToPILImage()(out_t)</span><br><span class="line">out_img</span><br></pre></td></tr></table></figure><img src="/2023/03/30/CycleGAN%E9%A2%84%E8%AE%AD%E7%BB%83/zebra1.jpg" class=""><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#opencv转换图像</span><br><span class="line">import numpy</span><br><span class="line">import cv2</span><br><span class="line">out_np = out.data.squeeze().cpu().numpy()</span><br><span class="line"># 将灰度图转换为BGR格式的彩色图</span><br><span class="line">out_img = cv2.cvtColor(out_np, cv2.COLOR_GRAY2BGR)</span><br><span class="line"></span><br><span class="line"># 显示图像</span><br><span class="line">cv2.imshow(&#x27;Output Image&#x27;, out_img)</span><br><span class="line">cv2.waitKey(0)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">out_img.save(<span class="string">r&quot;C:\Users\Hetmyer\Desktop\zebra1.jpg&quot;</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;em&gt;&lt;strong&gt;由.ipynb文件转化而成&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span cl</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="pytorch" scheme="http://example.com/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>ResNet预训练</title>
    <link href="http://example.com/2023/03/30/ResNet%E9%A2%84%E8%AE%AD%E7%BB%83/"/>
    <id>http://example.com/2023/03/30/ResNet%E9%A2%84%E8%AE%AD%E7%BB%83/</id>
    <published>2023-03-30T08:44:53.000Z</published>
    <updated>2023-03-30T09:07:51.734Z</updated>
    
    <content type="html"><![CDATA[<p><em><strong>由.ipynb文件转化而成</strong></em></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models</span><br></pre></td></tr></table></figure><p><strong>首字母大写的名称对应是实现了很多流行模型的python类，它们输入和输出之间操作的编排不同；首字母小写的名称是指用预定义的层和单元数实例化模型的函数，有时使用不同的参数集</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">dir</span>(models)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[&#x27;AlexNet&#x27;,</span><br><span class="line"> &#x27;DenseNet&#x27;,</span><br><span class="line"> &#x27;EfficientNet&#x27;,</span><br><span class="line"> &#x27;GoogLeNet&#x27;,</span><br><span class="line"> &#x27;GoogLeNetOutputs&#x27;,</span><br><span class="line"> &#x27;Inception3&#x27;,</span><br><span class="line"> &#x27;InceptionOutputs&#x27;,</span><br><span class="line"> &#x27;MNASNet&#x27;,</span><br><span class="line"> &#x27;MobileNetV2&#x27;,</span><br><span class="line"> &#x27;MobileNetV3&#x27;,</span><br><span class="line"> &#x27;RegNet&#x27;,</span><br><span class="line"> &#x27;ResNet&#x27;,</span><br><span class="line"> &#x27;ShuffleNetV2&#x27;,</span><br><span class="line"> &#x27;SqueezeNet&#x27;,</span><br><span class="line"> &#x27;VGG&#x27;,</span><br><span class="line"> &#x27;_GoogLeNetOutputs&#x27;,</span><br><span class="line"> &#x27;_InceptionOutputs&#x27;,</span><br><span class="line"> &#x27;__builtins__&#x27;,</span><br><span class="line"> &#x27;__cached__&#x27;,</span><br><span class="line"> &#x27;__doc__&#x27;,</span><br><span class="line"> &#x27;__file__&#x27;,</span><br><span class="line"> &#x27;__loader__&#x27;,</span><br><span class="line"> &#x27;__name__&#x27;,</span><br><span class="line"> &#x27;__package__&#x27;,</span><br><span class="line"> &#x27;__path__&#x27;,</span><br><span class="line"> &#x27;__spec__&#x27;,</span><br><span class="line"> &#x27;_utils&#x27;,</span><br><span class="line"> &#x27;alexnet&#x27;,</span><br><span class="line"> &#x27;densenet&#x27;,</span><br><span class="line"> &#x27;densenet121&#x27;,</span><br><span class="line"> &#x27;densenet161&#x27;,</span><br><span class="line"> &#x27;densenet169&#x27;,</span><br><span class="line"> &#x27;densenet201&#x27;,</span><br><span class="line"> &#x27;detection&#x27;,</span><br><span class="line"> &#x27;efficientnet&#x27;,</span><br><span class="line"> &#x27;efficientnet_b0&#x27;,</span><br><span class="line"> &#x27;efficientnet_b1&#x27;,</span><br><span class="line"> &#x27;efficientnet_b2&#x27;,</span><br><span class="line"> &#x27;efficientnet_b3&#x27;,</span><br><span class="line"> &#x27;efficientnet_b4&#x27;,</span><br><span class="line"> &#x27;efficientnet_b5&#x27;,</span><br><span class="line"> &#x27;efficientnet_b6&#x27;,</span><br><span class="line"> &#x27;efficientnet_b7&#x27;,</span><br><span class="line"> &#x27;feature_extraction&#x27;,</span><br><span class="line"> &#x27;googlenet&#x27;,</span><br><span class="line"> &#x27;inception&#x27;,</span><br><span class="line"> &#x27;inception_v3&#x27;,</span><br><span class="line"> &#x27;mnasnet&#x27;,</span><br><span class="line"> &#x27;mnasnet0_5&#x27;,</span><br><span class="line"> &#x27;mnasnet0_75&#x27;,</span><br><span class="line"> &#x27;mnasnet1_0&#x27;,</span><br><span class="line"> &#x27;mnasnet1_3&#x27;,</span><br><span class="line"> &#x27;mobilenet&#x27;,</span><br><span class="line"> &#x27;mobilenet_v2&#x27;,</span><br><span class="line"> &#x27;mobilenet_v3_large&#x27;,</span><br><span class="line"> &#x27;mobilenet_v3_small&#x27;,</span><br><span class="line"> &#x27;mobilenetv2&#x27;,</span><br><span class="line"> &#x27;mobilenetv3&#x27;,</span><br><span class="line"> &#x27;quantization&#x27;,</span><br><span class="line"> &#x27;regnet&#x27;,</span><br><span class="line"> &#x27;regnet_x_16gf&#x27;,</span><br><span class="line"> &#x27;regnet_x_1_6gf&#x27;,</span><br><span class="line"> &#x27;regnet_x_32gf&#x27;,</span><br><span class="line"> &#x27;regnet_x_3_2gf&#x27;,</span><br><span class="line"> &#x27;regnet_x_400mf&#x27;,</span><br><span class="line"> &#x27;regnet_x_800mf&#x27;,</span><br><span class="line"> &#x27;regnet_x_8gf&#x27;,</span><br><span class="line"> &#x27;regnet_y_16gf&#x27;,</span><br><span class="line"> &#x27;regnet_y_1_6gf&#x27;,</span><br><span class="line"> &#x27;regnet_y_32gf&#x27;,</span><br><span class="line"> &#x27;regnet_y_3_2gf&#x27;,</span><br><span class="line"> &#x27;regnet_y_400mf&#x27;,</span><br><span class="line"> &#x27;regnet_y_800mf&#x27;,</span><br><span class="line"> &#x27;regnet_y_8gf&#x27;,</span><br><span class="line"> &#x27;resnet&#x27;,</span><br><span class="line"> &#x27;resnet101&#x27;,</span><br><span class="line"> &#x27;resnet152&#x27;,</span><br><span class="line"> &#x27;resnet18&#x27;,</span><br><span class="line"> &#x27;resnet34&#x27;,</span><br><span class="line"> &#x27;resnet50&#x27;,</span><br><span class="line"> &#x27;resnext101_32x8d&#x27;,</span><br><span class="line"> &#x27;resnext50_32x4d&#x27;,</span><br><span class="line"> &#x27;segmentation&#x27;,</span><br><span class="line"> &#x27;shufflenet_v2_x0_5&#x27;,</span><br><span class="line"> &#x27;shufflenet_v2_x1_0&#x27;,</span><br><span class="line"> &#x27;shufflenet_v2_x1_5&#x27;,</span><br><span class="line"> &#x27;shufflenet_v2_x2_0&#x27;,</span><br><span class="line"> &#x27;shufflenetv2&#x27;,</span><br><span class="line"> &#x27;squeezenet&#x27;,</span><br><span class="line"> &#x27;squeezenet1_0&#x27;,</span><br><span class="line"> &#x27;squeezenet1_1&#x27;,</span><br><span class="line"> &#x27;vgg&#x27;,</span><br><span class="line"> &#x27;vgg11&#x27;,</span><br><span class="line"> &#x27;vgg11_bn&#x27;,</span><br><span class="line"> &#x27;vgg13&#x27;,</span><br><span class="line"> &#x27;vgg13_bn&#x27;,</span><br><span class="line"> &#x27;vgg16&#x27;,</span><br><span class="line"> &#x27;vgg16_bn&#x27;,</span><br><span class="line"> &#x27;vgg19&#x27;,</span><br><span class="line"> &#x27;vgg19_bn&#x27;,</span><br><span class="line"> &#x27;video&#x27;,</span><br><span class="line"> &#x27;wide_resnet101_2&#x27;,</span><br><span class="line"> &#x27;wide_resnet50_2&#x27;]</span><br></pre></td></tr></table></figure><p><strong>alexnet是一个可以运行AlexNet架构的对象，但是如果我们直接使用<code>output=alexnet(input)</code>运行正向传播，那将会使用整个网络的数据来产生输出。由于网络没有初始化，即它的权重没有经过训练，产生的输出毫无意义。所以，我们可以选择性地下载和加载预训练好的权重。</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">alexnet = models.AlexNet()</span><br></pre></td></tr></table></figure><p><strong>这里使用函数(首字母小写的)，没什么必要，只是为了方便使用与预训练好的网络的构建方式相匹配的层和单元数来实例化模型</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">resnet = models.resnet101(pretrained=<span class="literal">True</span>)<span class="comment">#pretrained=True，加载训练过的权重</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">resnet</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ResNet(</span><br><span class="line">  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)</span><br><span class="line">  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">  (relu): ReLU(inplace=True)</span><br><span class="line">  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)</span><br><span class="line">  (layer1): Sequential(</span><br><span class="line">    (0): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">  ....</span><br><span class="line">  ....</span><br><span class="line">  )</span><br><span class="line">  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))</span><br><span class="line">  (fc): Linear(in_features=2048, out_features=1000, bias=True)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p><strong>图像预处理，大小、颜色等，transforms提供了转换操作，是我们可以快速定义基本预处理函数的管道</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">preprocess = transforms.Compose([transforms.Resize(<span class="number">256</span>), </span><br><span class="line">                                transforms.CenterCrop(<span class="number">224</span>), </span><br><span class="line">                                transforms.ToTensor(), </span><br><span class="line">                                transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img = Image.<span class="built_in">open</span>(<span class="string">r&quot;H:\Text\data\squirrel_cls.jpg&quot;</span>)</span><br><span class="line">img</span><br></pre></td></tr></table></figure><img src="/2023/03/30/ResNet%E9%A2%84%E8%AE%AD%E7%BB%83/squirrel_cls.jpg" class=""><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img_t = preprocess(img)</span><br><span class="line">img_t.shape</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.Size([3, 224, 224])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">batch_t = torch.unsqueeze(img_t, <span class="number">0</span>)</span><br><span class="line">batch_t.shape <span class="comment">##(N,C, H, W)</span></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.Size([1, 3, 224, 224])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">resnet.<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ResNet(</span><br><span class="line">  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)</span><br><span class="line">  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">  (relu): ReLU(inplace=True)</span><br><span class="line">  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)</span><br><span class="line">  (layer1): Sequential(</span><br><span class="line">    (0): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">.......</span><br><span class="line">.......</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))</span><br><span class="line">  (fc): Linear(in_features=2048, out_features=1000, bias=True)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">out = resnet(batch_t)</span><br><span class="line">out.size(), out</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># out_t = (out.data.squeeze() + 1.0) / 2.0</span></span><br><span class="line"><span class="comment"># out_img = transforms.ToPILImage()(out_t)</span></span><br><span class="line"><span class="comment"># out_img 报错：ValueError: pic should be 2/3 dimensional. Got 1 dimensions.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ##opencv转换图像</span></span><br><span class="line"><span class="comment"># import numpy</span></span><br><span class="line"><span class="comment"># import cv2</span></span><br><span class="line"><span class="comment"># out_np = out.data.squeeze().cpu().numpy()</span></span><br><span class="line"><span class="comment"># # 将灰度图转换为BGR格式的彩色图</span></span><br><span class="line"><span class="comment"># out_img = cv2.cvtColor(out_np, cv2.COLOR_GRAY2BGR)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 显示图像</span></span><br><span class="line"><span class="comment"># cv2.imshow(&#x27;Output Image&#x27;, out_img)</span></span><br><span class="line"><span class="comment"># cv2.waitKey(0)</span></span><br><span class="line"><span class="comment"># cv2.destroyAllWindows()</span></span><br></pre></td></tr></table></figure><p><strong>在Python中，.strip()方法用于从字符串中删除前导或尾随的空格字符（例如空格、制表符或换行符）。</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">r&quot;G:\workspace\dlwpt-code\data\p1ch2\imagenet_classes.txt&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    labels = [line.strip() <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines()]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">labels</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[&#x27;tench, Tinca tinca&#x27;,</span><br><span class="line"> &#x27;goldfish, Carassius auratus&#x27;,</span><br><span class="line"> &#x27;great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias&#x27;,</span><br><span class="line"> &#x27;tiger shark, Galeocerdo cuvieri&#x27;,</span><br><span class="line"> &#x27;hammerhead, hammerhead shark&#x27;,</span><br><span class="line"> &#x27;electric ray, crampfish, numbfish, torpedo&#x27;,</span><br><span class="line"> &#x27;stingray&#x27;,</span><br><span class="line"> &#x27;cock&#x27;,</span><br><span class="line"> &#x27;hen&#x27;,</span><br><span class="line"> &#x27;ostrich, Struthio camelus&#x27;,</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line"> &#x27;hen-of-the-woods, hen of the woods, Polyporus frondosus, Grifola frondosa&#x27;,</span><br><span class="line"> &#x27;bolete&#x27;,</span><br><span class="line"> &#x27;ear, spike, capitulum&#x27;,</span><br><span class="line"> &#x27;toilet tissue, toilet paper, bathroom tissue&#x27;]</span><br></pre></td></tr></table></figure><p><strong>torch.max(input, dim&#x3D;None, keepdim&#x3D;False, out&#x3D;None)参数对应输入、列行、输出是否降维、输出位置；<br> 函数返回一个元组，其中第一个元素是张量中的最大值，第二个元素是最大值所在的索引。</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">_, index = torch.<span class="built_in">max</span>(out, <span class="number">1</span>)</span><br><span class="line">index[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tensor(335)</span><br></pre></td></tr></table></figure><p><strong>这行代码将通过softmax函数将张量out在第1维上进行归一化，使得输出的每个元素都在[0,1]范围内且和为1。然后，它选择第0个元素，将它乘以100，最终返回一个新的张量。这个张量的每个元素表示相应类别的概率百分比。</strong></p><p><strong>这里out是一个形状为(1, 1000)的张量，表示有1000个类别的预测分数，dim&#x3D;1表示对第二个维度进行操作，也就是对每个样本的1000个输出值进行操作，[0]表示取第一个样本，最后乘以100得到百分率常用表达形式</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">percentage = torch.nn.functional.softmax(out, dim=<span class="number">1</span>)[<span class="number">0</span>] * <span class="number">100</span> <span class="comment">##[0]，这里理解有点问题</span></span><br><span class="line">labels[index[<span class="number">0</span>]], percentage[index[<span class="number">0</span>]].item()</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(&#x27;fox squirrel, eastern fox squirrel, Sciurus niger&#x27;, 99.84718322753906)</span><br></pre></td></tr></table></figure><p><strong>enumerate() 是 Python 内置的函数之一，用于在迭代一个序列时同时获取每个元素的索引和对应的值。<br>在 for i, p in enumerate(percentage) 中，percentage 应该是一个序列（如列表或元组），i 是序列中每个元素的索引（从0开始），p 是对应的元素值。通过 enumerate() 函数，我们可以同时遍历序列的索引和值，使得在循环体内能够更方便地使用这两个值。</strong></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">percentage = [50, 75, 90, 100]</span><br><span class="line">for i, p in enumerate(percentage):</span><br><span class="line">    print(&quot;The percentage of completion for task&quot;, i, &quot;is&quot;, p, &quot;%.&quot;)</span><br><span class="line">##输出</span><br><span class="line">The percentage of completion for task 0 is 50%.</span><br><span class="line">The percentage of completion for task 1 is 75%.</span><br><span class="line">The percentage of completion for task 2 is 90%.</span><br><span class="line">The percentage of completion for task 3 is 100%.</span><br></pre></td></tr></table></figure><p><strong>列出“置信率”列表</strong></p><ol start="2"><li>第二种方式实现列出前五个较高的概率对应的类别</li></ol><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">probs = torch.nn.functional.softmax(out, dim=1)[0:5]</span><br><span class="line">top_probs, top_classes = probs.topk(k=3, dim=1)</span><br><span class="line">for i in range(5):</span><br><span class="line">    print(f&quot;Sample &#123;i&#125; top 3 classes with probabilities:&quot;)</span><br><span class="line">    for j in range(3):</span><br><span class="line">        print(f&quot;Class &#123;top_classes[i][j]&#125;: &#123;top_probs[i][j]*100:.2f&#125;%&quot;)</span><br></pre></td></tr></table></figure><p><strong>topk()函数可以在指定维度上返回前k个最大的元素以及它们的索引。在这里，我们指定k&#x3D;3表示返回前三个最大的概率值以及对应的类别索引。</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">_, indices = torch.sort(out, descending=<span class="literal">True</span>)</span><br><span class="line">[(labels[idx], percentage[idx].item()) <span class="keyword">for</span> idx <span class="keyword">in</span> indices[<span class="number">0</span>][:<span class="number">5</span>]]</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[(&#x27;fox squirrel, eastern fox squirrel, Sciurus niger&#x27;, 99.84718322753906),</span><br><span class="line"> (&#x27;hare&#x27;, 0.03233512118458748),</span><br><span class="line"> (&#x27;marmot&#x27;, 0.016555076465010643),</span><br><span class="line"> (&#x27;titi, titi monkey&#x27;, 0.012815508060157299),</span><br><span class="line"> (&#x27;guenon, guenon monkey&#x27;, 0.008419022895395756)]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numbers = [<span class="number">4</span>, <span class="number">2</span>, <span class="number">7</span>, <span class="number">1</span>, <span class="number">9</span>, <span class="number">5</span>]</span><br><span class="line"><span class="comment"># 使用sort()函数排序</span></span><br><span class="line">numbers.sort(reverse=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(numbers)  <span class="comment"># 输出 [1, 2, 4, 5, 7, 9]</span></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[9, 7, 5, 4, 2, 1]</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;em&gt;&lt;strong&gt;由.ipynb文件转化而成&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;%matplot</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="pytorch" scheme="http://example.com/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>0317_张量</title>
    <link href="http://example.com/2023/03/30/0317-%E5%BC%A0%E9%87%8F/"/>
    <id>http://example.com/2023/03/30/0317-%E5%BC%A0%E9%87%8F/</id>
    <published>2023-03-30T01:50:33.000Z</published>
    <updated>2023-03-30T09:09:40.159Z</updated>
    
    <content type="html"><![CDATA[<p><em><strong>由.ipynb文件转化而成</strong></em></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><h2 id="张量"><a href="#张量" class="headerlink" title="张量"></a>张量</h2><h4 id="使用随机数或者常数值"><a href="#使用随机数或者常数值" class="headerlink" title="使用随机数或者常数值"></a>使用随机数或者常数值</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">shape = (<span class="number">2</span>, <span class="number">3</span>, )</span><br><span class="line">x = torch.rand(shape)</span><br><span class="line">ones_tensor = torch.ones(shape)</span><br><span class="line">zeros_tensor = torch.zeros(shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Random tensor: \n <span class="subst">&#123;x&#125;</span> \n&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Ones tensor: \n <span class="subst">&#123;ones_tensor&#125;</span> \n&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Zeros tensor: \n <span class="subst">&#123;zeros_tensor&#125;</span> \n&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Random tensor: </span><br><span class="line"> tensor([[0.8369, 0.0547, 0.4424],</span><br><span class="line">        [0.1585, 0.9447, 0.7939]]) </span><br><span class="line"></span><br><span class="line">Ones tensor: </span><br><span class="line"> tensor([[1., 1., 1.],</span><br><span class="line">        [1., 1., 1.]]) </span><br><span class="line"></span><br><span class="line">Zeros tensor: </span><br><span class="line"> tensor([[0., 0., 0.],</span><br><span class="line">        [0., 0., 0.]]) </span><br></pre></td></tr></table></figure><h4 id="从一个张量生成"><a href="#从一个张量生成" class="headerlink" title="从一个张量生成"></a>从一个张量生成</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y = torch.ones_like(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Ones tensor: \n <span class="subst">&#123;y&#125;</span> \n&quot;</span>)</span><br><span class="line"></span><br><span class="line">new_ones = x.new_ones(x.shape) <span class="comment">#torch.ones_like与x.new_ones(x.shape)的区别在于，前者更加灵活而后者需要借鉴于x张量的数据类型、设备和size等信息</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;new_ones of tensor:\n <span class="subst">&#123;new_ones&#125;</span>\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">x_rand = torch.rand_like(x, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Random tensor: \n <span class="subst">&#123;x&#125;</span> \n&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Ones tensor: </span><br><span class="line"> tensor([[1., 1., 1.],</span><br><span class="line">        [1., 1., 1.]]) </span><br><span class="line"></span><br><span class="line">new_ones of tensor:</span><br><span class="line"> tensor([[1., 1., 1.],</span><br><span class="line">        [1., 1., 1.]])</span><br><span class="line"></span><br><span class="line">Random tensor: </span><br><span class="line"> tensor([[0.8369, 0.0547, 0.4424],</span><br><span class="line">        [0.1585, 0.9447, 0.7939]]) </span><br></pre></td></tr></table></figure><p>​    </p><h4 id="直接生成"><a href="#直接生成" class="headerlink" title="直接生成"></a>直接生成</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]]</span><br><span class="line">x_data = torch.tensor(data)</span><br><span class="line">x_data</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tensor([[1, 2],</span><br><span class="line">        [3, 4]])</span><br></pre></td></tr></table></figure><h4 id="来自numpy数组"><a href="#来自numpy数组" class="headerlink" title="来自numpy数组"></a>来自numpy数组</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#从numpy到tensor</span></span><br><span class="line">np_array = np.array(data)</span><br><span class="line">x_np = torch.from_numpy(np_array)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;从numpy到rensor:\n<span class="subst">&#123;x_np&#125;</span>\n&#x27;</span>)</span><br><span class="line"><span class="comment">#从tensor到numpy</span></span><br><span class="line">a = torch.eye(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">b = a.numpy()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;从tensor到numpy:\n<span class="subst">&#123;b&#125;</span>\n&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">从numpy到rensor:</span><br><span class="line">tensor([[1, 2],</span><br><span class="line">        [3, 4]], dtype=torch.int32)</span><br><span class="line"></span><br><span class="line">从tensor到numpy:</span><br><span class="line">[[1. 0.]</span><br><span class="line"> [0. 1.]]</span><br></pre></td></tr></table></figure><h4 id="其他："><a href="#其他：" class="headerlink" title="其他："></a>其他：</h4><ol><li>torch.randn()：生成一个标准正态分布的张量。</li><li>torch.arange()：生成一个指定范围内的等间隔数列张量,最后一个数表示步长。</li><li>torch.linspace()：生成一个指定范围内的等间隔数列张量,最后一个数表示生成的个数。</li><li>torch.randperm()：生成一个指定长度的随机排列张量等等。</li></ol><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(torch.randn(<span class="number">3</span>, <span class="number">5</span>))</span><br><span class="line"><span class="built_in">print</span>(torch.arange(<span class="number">0</span>, <span class="number">10</span>, <span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(torch.linspace(<span class="number">0</span>, <span class="number">10</span>, <span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(torch.randperm(<span class="number">10</span>))</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tensor([[ 0.5694, -0.6243, -0.4994, -0.8550,  1.3709],</span><br><span class="line">        [ 0.9162, -0.2351, -0.1119, -1.6594,  1.3573],</span><br><span class="line">        [-1.8149,  0.3975,  0.0402,  0.3078,  0.9530]])</span><br><span class="line">tensor([0, 2, 4, 6, 8])</span><br><span class="line">tensor([ 0.,  5., 10.])</span><br><span class="line">tensor([1, 0, 3, 5, 9, 7, 6, 2, 4, 8])</span><br></pre></td></tr></table></figure><h3 id="张量的属性"><a href="#张量的属性" class="headerlink" title="张量的属性"></a>张量的属性</h3><p>在PyTorch中，张量（Tensor）是一种包含数值的多维数组，是PyTorch中最基本的数据类型之一。每个张量都具有一些重要的属性，包括：</p><p>. dtype：表示张量中元素的数据类型，例如float32、int64、bool等。</p><p>. device：表示张量所在的设备（如CPU或GPU）。</p><p>. shape（或size）：表示张量的形状（或维度），如(2, 3)、(4, 3, 2)等。</p><p>. requires_grad：表示张量是否需要进行梯度计算，用于实现自动求导功能。</p><p>除了这些常见的属性之外，还有一些其他的属性，例如：</p><p>. layout：表示张量的存储方式（如strided、sparse等）。</p><p>. strides：表示张量在内存中的步长（stride）。</p><p>. is_pinned：表示张量是否存储在固定的内存位置（如CPU的页锁定内存）。</p><p>. dim（或ndim）：表示张量的维度数，等同于shape的长度。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tensor = torch.rand(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Shape of tensor: \n <span class="subst">&#123;tensor.shape&#125;</span> \n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Size() of tensor: \n <span class="subst">&#123;tensor.size()&#125;</span> \n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Size of tensor: \n <span class="subst">&#123;tensor.size&#125;</span> \n&quot;</span>)<span class="comment">######与第二个有区别</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Datatype of tensor: \n <span class="subst">&#123;tensor.dtype&#125;</span> \n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Device tensor is stored: \n <span class="subst">&#123;tensor.device&#125;</span> \n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Number of tensor: \n <span class="subst">&#123;tensor.numel()&#125;</span> \n&quot;</span>)<span class="comment">######张量元素个数</span></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Shape of tensor: </span><br><span class="line"> torch.Size([5, 3]) </span><br><span class="line"></span><br><span class="line">Size() of tensor: </span><br><span class="line"> torch.Size([5, 3]) </span><br><span class="line"></span><br><span class="line">Size of tensor: </span><br><span class="line"> &lt;built-in method size of Tensor object at 0x000001302B05CB30&gt; </span><br><span class="line"></span><br><span class="line">Datatype of tensor: </span><br><span class="line"> torch.float32 </span><br><span class="line"></span><br><span class="line">Device tensor is stored: </span><br><span class="line"> cpu </span><br><span class="line"></span><br><span class="line">Number of tensor: </span><br><span class="line"> 15 </span><br></pre></td></tr></table></figure><p>​    </p><h3 id="张量的运算"><a href="#张量的运算" class="headerlink" title="张量的运算"></a>张量的运算</h3><h4 id="更换设备cuda-or-cpu"><a href="#更换设备cuda-or-cpu" class="headerlink" title="更换设备cuda or cpu"></a>更换设备cuda or cpu</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># is_available 函数判断是否有cuda可以使用</span></span><br><span class="line"><span class="comment"># ``torch.device``将张量移动到指定的设备中</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span>)          <span class="comment"># a CUDA 设备对象</span></span><br><span class="line">    y = torch.ones_like(x, device=device)  <span class="comment"># 直接从GPU创建张量</span></span><br><span class="line">    x = x.to(device)                       <span class="comment"># 或者直接使用``.to(&quot;cuda&quot;)``将张量移动到cuda中</span></span><br><span class="line">    z = x + y</span><br><span class="line">    <span class="built_in">print</span>(z)</span><br><span class="line">    <span class="built_in">print</span>(z.to(<span class="string">&quot;cpu&quot;</span>, torch.double))       <span class="comment"># ``.to`` 也会对变量的类型做更改</span></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tensor([[1.8369, 1.0547, 1.4424],</span><br><span class="line">        [1.1585, 1.9447, 1.7939]], device=&#x27;cuda:0&#x27;)</span><br><span class="line">tensor([[1.8369, 1.0547, 1.4424],</span><br><span class="line">        [1.1585, 1.9447, 1.7939]], dtype=torch.float64)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tensor = torch.eye(<span class="number">4</span>, <span class="number">4</span>).to(device)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;第一列：\n <span class="subst">&#123;tensor[:, <span class="number">0</span>]&#125;</span> \n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;device of tensor: \n <span class="subst">&#123;tensor.device&#125;</span>\n&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">第一列：</span><br><span class="line"> tensor([1., 0., 0., 0.], device=&#x27;cuda:0&#x27;) </span><br><span class="line"></span><br><span class="line">device of tensor: </span><br><span class="line"> cuda:0</span><br></pre></td></tr></table></figure><p>​    </p><h4 id="拼接张量"><a href="#拼接张量" class="headerlink" title="拼接张量"></a>拼接张量</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">t1 = torch.cat([tensor, tensor, tensor], dim = <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;t1&#125;</span>\n&#x27;</span>)</span><br><span class="line">t2 = torch.cat([tensor, tensor, tensor], dim = <span class="number">0</span>)<span class="comment">##dim行列式，先行0后列1</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;t2&#125;</span>\n&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tensor([[1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.],</span><br><span class="line">        [0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],</span><br><span class="line">        [0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.],</span><br><span class="line">        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.]], device=&#x27;cuda:0&#x27;)</span><br><span class="line"></span><br><span class="line">tensor([[1., 0., 0., 0.],</span><br><span class="line">        [0., 1., 0., 0.],</span><br><span class="line">        [0., 0., 1., 0.],</span><br><span class="line">        [0., 0., 0., 1.],</span><br><span class="line">        [1., 0., 0., 0.],</span><br><span class="line">        [0., 1., 0., 0.],</span><br><span class="line">        [0., 0., 1., 0.],</span><br><span class="line">        [0., 0., 0., 1.],</span><br><span class="line">        [1., 0., 0., 0.],</span><br><span class="line">        [0., 1., 0., 0.],</span><br><span class="line">        [0., 0., 1., 0.],</span><br><span class="line">        [0., 0., 0., 1.]], device=&#x27;cuda:0&#x27;)</span><br></pre></td></tr></table></figure><p>​    </p><h4 id="各种运算"><a href="#各种运算" class="headerlink" title="各种运算"></a>各种运算</h4><p>在PyTorch中，张量之间可以进行各种算术运算，包括：</p><p>. 加法运算：使用+运算符或.add()函数进行元素级别的加法运算。</p><p>. 减法运算：使用-运算符或.sub()函数进行元素级别的减法运算。</p><p>. 乘法运算：使用*运算符或.mul()函数进行元素级别的乘法运算。</p><p>. 除法运算：使用&#x2F;运算符或.div()函数进行元素级别的除法运算。</p><p>. 矩阵乘法运算：使用@运算符或.matmul()函数进行矩阵乘法运算。</p><p>. 广播运算：当张量形状不同但满足广播规则时，可以使用广播运算进行相应运算。</p><p><strong>广播</strong>（broadcasting）是张量运算中的一种机制，它可以自动地对不同形状的张量进行适当地扩展，使它们具有相同的形状，从而进行逐元素的运算。</p><p>广播规则如下：</p><ol><li>如果两个张量的形状完全相同，它们可以直接进行逐元素的运算，不需要进行广播。</li><li>如果两个张量在某一维的长度相同，或者其中一个张量在该维的长度为1，那么这两个张量在该维上是可以进行广播的。</li><li>如果两个张量在某一维的长度不同且都不为1，则不能进行广播，此时运算会报错。</li></ol><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.randn(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">y = torch.randn(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">result = torch.empty(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">torch.add(x, y, out=result)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;result加法运算使用输出tensor作为参数：\n<span class="subst">&#123;result&#125;</span>\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;加法运算：\n <span class="subst">&#123;x + y&#125;</span>\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;减法运算：\n <span class="subst">&#123;x - y&#125;</span>\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;乘法运算：\n <span class="subst">&#123;x * y&#125;</span>\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;除法运算：\n <span class="subst">&#123;x / y&#125;</span>\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;矩阵乘法运算：\n <span class="subst">&#123;x @ y&#125;</span>\n&quot;</span>)</span><br><span class="line">z = torch.rand(<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;广播运算：\n <span class="subst">&#123;x + z&#125;</span>\n&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">result加法运算使用输出tensor作为参数：</span><br><span class="line">tensor([[-0.4263, -0.6711,  0.5440],</span><br><span class="line">        [-0.7237, -0.8811,  2.0019],</span><br><span class="line">        [ 0.4477,  0.8981, -0.1444]])</span><br><span class="line"></span><br><span class="line">加法运算：</span><br><span class="line"> tensor([[-0.4263, -0.6711,  0.5440],</span><br><span class="line">        [-0.7237, -0.8811,  2.0019],</span><br><span class="line">        [ 0.4477,  0.8981, -0.1444]])</span><br><span class="line"></span><br><span class="line">减法运算：</span><br><span class="line"> tensor([[ 0.1459,  0.7861, -0.3823],</span><br><span class="line">        [-0.9483,  1.3394, -1.6570],</span><br><span class="line">        [ 0.5651,  1.0449,  0.9603]])</span><br><span class="line"></span><br><span class="line">乘法运算：</span><br><span class="line"> tensor([[ 0.0401, -0.0419,  0.0375],</span><br><span class="line">        [-0.0939, -0.2544,  0.3155],</span><br><span class="line">        [-0.0297, -0.0713, -0.2253]])</span><br><span class="line"></span><br><span class="line">除法运算：</span><br><span class="line"> tensor([[  0.4901,  -0.0790,   0.1746],</span><br><span class="line">        [ -7.4428,  -0.2064,   0.0943],</span><br><span class="line">        [ -8.6269, -13.2379,  -0.7386]])</span><br><span class="line"></span><br><span class="line">矩阵乘法运算：</span><br><span class="line"> tensor([[ 0.0418,  0.0323, -0.0044],</span><br><span class="line">        [ 0.2548,  0.3420, -0.0632],</span><br><span class="line">        [-0.0597, -1.4775,  1.7865]])</span><br><span class="line"></span><br><span class="line">广播运算：</span><br><span class="line"> tensor([[ 0.5688,  0.7969,  0.4292],</span><br><span class="line">        [-0.1270,  0.9685,  0.5208],</span><br><span class="line">        [ 1.2154,  1.7109,  0.7563]])</span><br></pre></td></tr></table></figure><p>​    </p><p>*** 就地操作 ：任何 以<code>_</code> 结尾的操作都会用结果替换原变量. 例如: <code>x.copy_(y)</code>, <code>x.t_()##就地转置操作</code>, 都会改变 <code>x</code>.***</p><p>*** torch.view 与Numpy的reshape类似 ***</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">t3 = torch.rand(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">tx = t3.view(<span class="number">2</span>, <span class="number">8</span>)</span><br><span class="line">ty = t3.view(-<span class="number">1</span>, <span class="number">2</span>)<span class="comment">###自动适应张量尺寸</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;原张量：<span class="subst">&#123;t3&#125;</span>\n\n 变后张量：\n<span class="subst">&#123;tx&#125;</span>\n\n -1变后张量：\n<span class="subst">&#123;ty&#125;</span>\n\n&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">原张量：tensor([[0.3388, 0.5605, 0.9860, 0.2639],</span><br><span class="line">        [0.7387, 0.6771, 0.7769, 0.0295],</span><br><span class="line">        [0.6652, 0.8719, 0.4755, 0.5013],</span><br><span class="line">        [0.7489, 0.0994, 0.4651, 0.4536]])</span><br><span class="line"></span><br><span class="line"> 变后张量：</span><br><span class="line">tensor([[0.3388, 0.5605, 0.9860, 0.2639, 0.7387, 0.6771, 0.7769, 0.0295],</span><br><span class="line">        [0.6652, 0.8719, 0.4755, 0.5013, 0.7489, 0.0994, 0.4651, 0.4536]])</span><br><span class="line"></span><br><span class="line"> -1变后张量：</span><br><span class="line">tensor([[0.3388, 0.5605],</span><br><span class="line">        [0.9860, 0.2639],</span><br><span class="line">        [0.7387, 0.6771],</span><br><span class="line">        [0.7769, 0.0295],</span><br><span class="line">        [0.6652, 0.8719],</span><br><span class="line">        [0.4755, 0.5013],</span><br><span class="line">        [0.7489, 0.0994],</span><br><span class="line">        [0.4651, 0.4536]])</span><br><span class="line">​    </span><br></pre></td></tr></table></figure><p>*** .item()是一个PyTorch中的函数，用于获取张量中的一个元素，将其转换为Python中的标量（scalar）值，并返回这个标量值。如果张量包含多个元素，.item()只会返回其中的一个元素，通常情况下是第一个元素。***</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">3.14</span>])</span><br><span class="line">y = x.item()</span><br><span class="line">y</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">3.140000104904175</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;em&gt;&lt;strong&gt;由.ipynb文件转化而成&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span cl</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="pytorch" scheme="http://example.com/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>Python常用函数</title>
    <link href="http://example.com/2023/03/26/Python%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"/>
    <id>http://example.com/2023/03/26/Python%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/</id>
    <published>2023-03-26T10:46:11.000Z</published>
    <updated>2023-03-26T10:54:49.724Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Python常用函数"><a href="#Python常用函数" class="headerlink" title="Python常用函数"></a>Python常用函数</h2><h2 id="filter-函数"><a href="#filter-函数" class="headerlink" title="filter()函数"></a>filter()函数</h2><p><em><strong>过滤用的，对象可以是几何、列表、元组，两个参数：前者过滤条件后者待过滤对象</strong></em></p><p><code>filter()</code>函数是Python内置函数之一，它用于从可迭代对象中过滤出满足特定条件的元素，并将它们组成一个新的迭代器返回。</p><p><code>filter()</code>函数的基本语法如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">filter</span>(function, iterable)</span><br></pre></td></tr></table></figure><p>其中，<code>function</code>是一个函数，用于对<code>iterable</code>中的每个元素进行判断，如果返回值为<code>True</code>，则将该元素包含在返回的迭代器中。<code>iterable</code>表示需要过滤的可迭代对象，如列表、元组、集合等。</p><p>下面是一个简单的例子，演示如何使用<code>filter()</code>函数从列表中过滤出偶数：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numbers = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]</span><br><span class="line">even_numbers = <span class="built_in">filter</span>(<span class="keyword">lambda</span> x: x % <span class="number">2</span> == <span class="number">0</span>, numbers)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(even_numbers))  <span class="comment"># 输出 [2, 4, 6, 8]</span></span><br></pre></td></tr></table></figure><p>在上面的代码中，我们使用<code>filter()</code>函数和Lambda函数从<code>numbers</code>列表中过滤出偶数，并将它们保存在新的变量<code>even_numbers</code>中。由于<code>filter()</code>函数返回的是一个迭代器，因此我们将它转换成列表并打印出来。</p><p>除了Lambda函数之外，我们还可以使用命名函数作为<code>function</code>参数传递给<code>filter()</code>函数。例如，下面的代码使用一个命名函数从字符串列表中过滤出长度大于等于5的字符串：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fruits = [<span class="string">&#x27;banana&#x27;</span>, <span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;orange&#x27;</span>, <span class="string">&#x27;kiwi&#x27;</span>]</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">is_long_string</span>(<span class="params">s</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>(s) &gt;= <span class="number">5</span></span><br><span class="line">long_strings = <span class="built_in">filter</span>(is_long_string, fruits)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(long_strings))  <span class="comment"># 输出 [&#x27;banana&#x27;, &#x27;orange&#x27;]</span></span><br></pre></td></tr></table></figure><p>在上面的代码中，我们定义了一个名为<code>is_long_string()</code>的函数，它接受一个字符串作为参数，并返回该字符串的长度是否大于等于5。然后我们将该函数传递给<code>filter()</code>函数，并从<code>fruits</code>列表中过滤出长度大于等于5的字符串。</p><p><code>filter()</code>函数是一个非常有用的函数，它可以帮助我们从可迭代对象中过滤出特定条件的元素，从而简化我们的代码。</p><h2 id="sorted-和sort-函数"><a href="#sorted-和sort-函数" class="headerlink" title="sorted()和sort()函数"></a>sorted()和sort()函数</h2><p>区别：</p><ol><li>修改原始对象</li></ol><p><code>sort()</code>函数是一个列表方法，它可以<strong>修改</strong>原始列表并将其按照指定方式进行排序。而<code>sorted()</code>函数是一个内置函数，它<strong>不会修改</strong>原始对象，而是返回一个新的已排序的列表。</p><ol><li>返回值</li></ol><p><code>sort()</code>函数<strong>不会返回任何值</strong>，它只会将原始列表排序。而<code>sorted()</code>函数会<strong>返回一个新的已排序的列表</strong>。</p><ol><li>可排序对象</li></ol><p><code>sort()</code>函数只能用于<strong>列表对象</strong>，因为它是一个列表方法。而<code>sorted()</code>函数可以用于<strong>任何可迭代对象，如元组、集合、字符串等</strong>。</p><ol><li>参数</li></ol><p><code>sort()</code>函数只接受<strong>两个</strong>可选参数：<code>key</code>和<code>reverse</code>。其中，<code>key</code>参数用于指定排序时使用的函数，<code>reverse</code>参数用于控制排序方式。而<code>sorted()</code>函数接受<strong>三个</strong>参数：<code>iterable</code>、<code>key</code>和<code>reverse</code>，其中<code>iterable</code>表示需要排序的可迭代对象。<strong>默认降序，True为升序</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numbers = [<span class="number">4</span>, <span class="number">2</span>, <span class="number">7</span>, <span class="number">1</span>, <span class="number">9</span>, <span class="number">5</span>]</span><br><span class="line"><span class="comment"># 使用sort()函数排序</span></span><br><span class="line">numbers.sort()</span><br><span class="line"><span class="built_in">print</span>(numbers)  <span class="comment"># 输出 [1, 2, 4, 5, 7, 9]</span></span><br><span class="line"></span><br><span class="line">numbers = [<span class="number">4</span>, <span class="number">2</span>, <span class="number">7</span>, <span class="number">1</span>, <span class="number">9</span>, <span class="number">5</span>]</span><br><span class="line"><span class="comment"># 使用sorted()函数排序</span></span><br><span class="line">sorted_numbers = <span class="built_in">sorted</span>(numbers)</span><br><span class="line"><span class="built_in">print</span>(sorted_numbers)  <span class="comment"># 输出 [1, 2, 4, 5, 7, 9]</span></span><br><span class="line"><span class="built_in">print</span>(numbers)  <span class="comment"># 输出 [4, 2, 7, 1, 9, 5]</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Python常用函数&quot;&gt;&lt;a href=&quot;#Python常用函数&quot; class=&quot;headerlink&quot; title=&quot;Python常用函数&quot;&gt;&lt;/a&gt;Python常用函数&lt;/h2&gt;&lt;h2 id=&quot;filter-函数&quot;&gt;&lt;a href=&quot;#filter-函数&quot; c</summary>
      
    
    
    
    <category term="编程语言" scheme="http://example.com/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"/>
    
    
    <category term="Python" scheme="http://example.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python高级用法</title>
    <link href="http://example.com/2023/03/26/Python%E9%AB%98%E7%BA%A7%E7%94%A8%E6%B3%95/"/>
    <id>http://example.com/2023/03/26/Python%E9%AB%98%E7%BA%A7%E7%94%A8%E6%B3%95/</id>
    <published>2023-03-26T10:45:51.000Z</published>
    <updated>2023-03-26T11:01:16.483Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Python高级用法"><a href="#Python高级用法" class="headerlink" title="Python高级用法"></a>Python高级用法</h2><p>Python 作为一门强大的编程语言，具有许多高级用法。以下是一些常见的高级用法：</p><ol><li>生成器表达式和生成器函数：生成器允许按需产生一个序列，而不是一次性将整个序列加载到内存中。生成器表达式和生成器函数都是创建生成器的方式，它们可以在循环中用于处理大型数据集，而无需将整个数据集存储在内存中。</li><li>装饰器：装饰器是一种Python语法，用于修改或增强函数或类的功能。装饰器通常用于AOP（面向切面编程），其中在函数或方法调用前后执行其他代码。</li><li>上下文管理器：上下文管理器是Python的一种语法，用于管理资源（如文件、网络连接等）。使用with语句可以自动管理上下文，从而确保资源在使用完后被正确释放。</li><li>多线程和多进程：Python允许同时执行多个线程和进程，从而提高程序的并发性和性能。使用多线程和多进程可以充分利用多核处理器，从而加快计算速度。</li><li>正则表达式：正则表达式是一种强大的文本处理工具，可以用于查找、替换和解析文本。Python内置了re模块，用于支持正则表达式操作。</li><li>面向对象编程：Python是一种面向对象编程语言，支持类、继承、多态等特性。使用面向对象编程可以将程序分解为更小的、易于管理的组件，从而提高代码的可读性和可维护性。</li><li>Lambda表达式：Lambda表达式是一种匿名函数，可以用于简化代码并增强可读性。Lambda表达式通常用于函数式编程，其中函数是一等公民，可以作为参数传递给其他函数。</li><li>列表推导式和字典推导式：推导式是一种简洁的语法，用于快速创建列表、字典等数据结构。列表推导式和字典推导式可以用于生成符合特定条件的数据结构。</li></ol><h2 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h2><p>yield是Python中的一个关键字，用于定义生成器函数。生成器是一种特殊的函数，它不会像普通函数一样一次性返回所有结果，而是可以根据需要<strong>逐步生成</strong>结果。这种逐步生成的过程可以大大减少内存占用，特别是在处理大数据集时非常有用。</p><p>下面是一个使用yield定义生成器函数的示例：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">square_numbers</span>(<span class="params">numbers</span>):</span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> numbers:</span><br><span class="line">        <span class="keyword">yield</span> n*n</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用生成器函数</span></span><br><span class="line">numbers = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line"><span class="keyword">for</span> square <span class="keyword">in</span> square_numbers(numbers):</span><br><span class="line">    <span class="built_in">print</span>(square)</span><br></pre></td></tr></table></figure><p>这段代码定义了一个名为square_numbers的生成器函数，它将一个列表中的数字平方后逐个生成结果。在使用生成器函数时，可以通过for循环来逐个获取结果。注意，这里的生成器函数不会一次性返回所有结果，而是根据需要逐步生成结果。</p><p>除了<strong>使用for循环</strong>来逐个获取生成器函数的结果之外，还可以使用<strong>next()函数</strong>来获取下一个结果，例如：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">square_numbers</span>(<span class="params">numbers</span>):</span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> numbers:</span><br><span class="line">        <span class="keyword">yield</span> n*n</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用生成器函数</span></span><br><span class="line">numbers = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">squares = square_numbers(numbers)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(squares)) <span class="comment"># 输出：1</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(squares)) <span class="comment"># 输出：4</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(squares)) <span class="comment"># 输出：9</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(squares)) <span class="comment"># 输出：16</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(squares)) <span class="comment"># 输出：25</span></span><br></pre></td></tr></table></figure><p>这里使用next()函数逐个获取生成器函数的结果，当没有更多结果时，会抛出StopIteration异常。</p><p>常用示例：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成器函数示例</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fibonacci</span>():</span><br><span class="line">    a, b = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="keyword">yield</span> a</span><br><span class="line">        a, b = b, a + b</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用生成器函数</span></span><br><span class="line"><span class="keyword">for</span> i, num <span class="keyword">in</span> <span class="built_in">enumerate</span>(fibonacci()):</span><br><span class="line">    <span class="keyword">if</span> i &gt;= <span class="number">10</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="built_in">print</span>(num)</span><br></pre></td></tr></table></figure><p>总之，yield是Python中非常有用的一个关键字，它可以用于定义生成器函数，逐步生成结果，减少内存占用。</p><h2 id="Lambda表达式"><a href="#Lambda表达式" class="headerlink" title="Lambda表达式"></a>Lambda表达式</h2><p>Lambda表达式是一种匿名函数，可以在需要函数对象的任何地方使用它。它的语法形式是<code>lambda arguments: expression</code>，其中arguments是函数的参数，expression是函数的返回值。Lambda函数可以包含任意数量的参数，但只能有一个表达式。</p><p>下面是一个简单的Lambda函数示例，它接受两个参数并返回它们的和：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sum</span> = <span class="keyword">lambda</span> x, y: x + y</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">sum</span>(<span class="number">3</span>, <span class="number">4</span>))  <span class="comment"># 输出 7</span></span><br></pre></td></tr></table></figure><p>其他示例：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">items = &#123;<span class="string">&#x27;apple&#x27;</span>: <span class="number">10</span>, <span class="string">&#x27;banana&#x27;</span>: <span class="number">5</span>, <span class="string">&#x27;orange&#x27;</span>: <span class="number">20</span>&#125;</span><br><span class="line">sorted_items = <span class="built_in">sorted</span>(items.items(), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(sorted_items)  <span class="comment"># 输出 [(&#x27;banana&#x27;, 5), (&#x27;apple&#x27;, 10), (&#x27;orange&#x27;, 20)]</span></span><br><span class="line"></span><br><span class="line">numbers = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]</span><br><span class="line">odd_numbers = <span class="built_in">list</span>(<span class="built_in">filter</span>(<span class="keyword">lambda</span> x: x % <span class="number">2</span> != <span class="number">0</span>, numbers))</span><br><span class="line"><span class="built_in">print</span>(odd_numbers)  <span class="comment"># 输出 [1, 3, 5, 7, 9]</span></span><br><span class="line"></span><br><span class="line">numbers = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]</span><br><span class="line">squares = [x**<span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> numbers <span class="keyword">if</span> x % <span class="number">2</span> == <span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(squares)  <span class="comment"># 输出 [4, 16, 36, 64]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="Os-Module"><a href="#Os-Module" class="headerlink" title="Os Module"></a>Os Module</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">os.name：返回导入的操作系统依赖模块的名称。</span><br><span class="line"></span><br><span class="line">os.getcwd()：返回当前工作目录。</span><br><span class="line"></span><br><span class="line">os.chdir(path)：将当前工作目录更改为给定路径。</span><br><span class="line"></span><br><span class="line">os.listdir(path=&quot;.&quot;): 返回路径中所有文件和目录的列表。</span><br><span class="line"></span><br><span class="line">os.mkdir(path)：使用给定的路径创建一个新目录。</span><br><span class="line"></span><br><span class="line">os.makedirs(path)：使用给定路径创建目录及其所有父目录。</span><br><span class="line"></span><br><span class="line">os.rmdir(path)：删除具有给定路径的目录。</span><br><span class="line"></span><br><span class="line">os.remove(path)：删除具有给定路径的文件。</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">##os.path.abspath(path)：返回路径名的规范化绝对化版本。</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os </span><br><span class="line"><span class="comment"># 获取当前文件的绝对路径</span></span><br><span class="line">absolute_path = os.path.abspath(__file__)</span><br><span class="line"><span class="built_in">print</span>(absolute_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取当前工作目录的绝对路径</span></span><br><span class="line">cwd_absolute_path = os.path.abspath(<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(cwd_absolute_path)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">##os.path.join(path1[, path2[, ...]])：连接两个或多个路径组件，在它们之间添加分隔符。</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># 示例1</span></span><br><span class="line">path1 = <span class="string">&#x27;/home/user&#x27;</span></span><br><span class="line">path2 = <span class="string">&#x27;documents&#x27;</span></span><br><span class="line">path3 = <span class="string">&#x27;example.txt&#x27;</span></span><br><span class="line">full_path = os.path.join(path1, path2, path3)</span><br><span class="line"><span class="built_in">print</span>(full_path)    <span class="comment"># /home/user/documents/example.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例2</span></span><br><span class="line">file_name = <span class="string">&#x27;config.txt&#x27;</span></span><br><span class="line">config_dir = os.path.join(os.environ[<span class="string">&#x27;HOME&#x27;</span>], <span class="string">&#x27;.config&#x27;</span>, <span class="string">&#x27;myapp&#x27;</span>)</span><br><span class="line">full_path = os.path.join(config_dir, file_name)</span><br><span class="line"><span class="built_in">print</span>(full_path)    <span class="comment"># /home/user/.config/myapp/config.txt</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Python高级用法&quot;&gt;&lt;a href=&quot;#Python高级用法&quot; class=&quot;headerlink&quot; title=&quot;Python高级用法&quot;&gt;&lt;/a&gt;Python高级用法&lt;/h2&gt;&lt;p&gt;Python 作为一门强大的编程语言，具有许多高级用法。以下是一些常见的高级</summary>
      
    
    
    
    <category term="编程语言" scheme="http://example.com/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"/>
    
    
    <category term="Python" scheme="http://example.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>实用小知识</title>
    <link href="http://example.com/2023/03/23/%E5%AE%9E%E7%94%A8%E5%B0%8F%E7%9F%A5%E8%AF%86/"/>
    <id>http://example.com/2023/03/23/%E5%AE%9E%E7%94%A8%E5%B0%8F%E7%9F%A5%E8%AF%86/</id>
    <published>2023-03-23T06:00:59.000Z</published>
    <updated>2023-10-20T10:56:37.024Z</updated>
    
    <content type="html"><![CDATA[<h2 id="pycharm常用快捷键"><a href="#pycharm常用快捷键" class="headerlink" title="pycharm常用快捷键"></a>pycharm常用快捷键</h2><p>常用的PyCharm快捷键：</p><ul><li>Alt + Enter：解决问题和提示修复建议</li><li>Ctrl + Alt + L：格式化代码  #美观</li><li>Ctrl + Alt + I：自动缩进       #按照语法要求进行缩进</li><li>Ctrl + &#x2F;：注释&#x2F;取消注释代码</li><li>Ctrl + W：选择代码块</li><li>Ctrl + Alt + T：把代码放入一个try&#x2F;except块</li><li>Ctrl + Shift + F7：高亮显示选中的变量</li><li>Alt + Shift + F：重构代码</li><li>Ctrl + Shift + F10：运行代码</li><li>Ctrl + Shift + F9：调试代码</li></ul><h2 id="Typora常用快捷键"><a href="#Typora常用快捷键" class="headerlink" title="Typora常用快捷键"></a>Typora常用快捷键</h2><ol><li>标题：Ctrl + 数字键（1~6）</li><li>加粗：Ctrl + B</li><li>表格：Ctrl + T</li><li>斜体：Ctrl + I</li><li>插入链接：Ctrl + K</li><li>引用：Ctrl + Shift + Q</li><li>代码块：Ctrl + Shift + K</li><li>插入图片：Ctrl + Shift + I</li><li>有序列表：Ctrl + Shift + [</li><li>无序列表：Ctrl + Shift + ]</li><li>删除线：Alt + Shift + 5</li><li>目录：[TOC] + Enter</li><li>序列图：&#96;&#96;&#96;mermaid + Enter</li><li>指定编程语言：&#96;&#96;&#96;python + Enter</li></ol><h2 id="Anaconda"><a href="#Anaconda" class="headerlink" title="Anaconda"></a>Anaconda</h2><h3 id="软件源删增"><a href="#软件源删增" class="headerlink" title="软件源删增"></a>软件源删增</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">##Anaconda清华源</span><br><span class="line">- https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/</span><br><span class="line"> - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge</span><br><span class="line"> - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line"> - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</span><br></pre></td></tr></table></figure><p>要从Conda配置中<strong>删除部分源</strong>，请使用以下命令：</p><p> 首先，列出当前已配置的所有Conda源：<br><code>conda config --show channels</code><br>然后，从上一步骤中列出的输出中找到您想要删除的源，并使用以下命令从配置中删除它：<br><code>conda config --remove channels &lt;channel_name&gt;</code><br> 其中，<channel_name> 是您要删除的源的名称。</p><p>最后，再次运行 <code>conda config --show channels</code> 确认源已被成功删除。</p><p>请注意，如果您从配置中删除了某个源，您将无法再从该源下载任何包。如果您将来需要该源，您可以使用以下命令将其重新<strong>添加到配置</strong>中：<br><code>conda config --add channels &lt;channel_name&gt;</code><br>其中，<channel_name> 是您要添加的源的名称</p><h2 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h2><h3 id="git-clone技巧"><a href="#git-clone技巧" class="headerlink" title="git clone技巧"></a>git clone技巧</h3><p>例如：<code>git clone https://github.com/torch/distro.git ~/torch --recursive</code>后者一为放置路径，二是为了递归克隆 Torch 框架所依赖的所有子模块。</p><h2 id="Pip"><a href="#Pip" class="headerlink" title="Pip"></a>Pip</h2><h3 id="Pip升级"><a href="#Pip升级" class="headerlink" title="Pip升级"></a>Pip升级</h3><p>要升级pip本身，可以使用以下命令：</p><p><code>python -m pip install --upgrade pip</code><br>这将会升级pip到最新版本。</p><p>如果您想要升级某个已安装的Python包，可以使用以下命令：<br><code>pip install --upgrade package_name</code><br>将package_name替换为您想要升级的包的名称。如果您想要升级所有已安装的包，可以使用以下命令：<br><code>pip freeze --local | grep -v &#39;^\-e&#39; | cut -d = -f 1  | xargs -n1 pip install -U</code><br>这将会列出所有已安装的包，并将它们全部升级到最新版本。</p><h3 id="Pip软件源"><a href="#Pip软件源" class="headerlink" title="Pip软件源"></a>Pip软件源</h3><ol><li><strong>国内主要镜像源</strong>：</li></ol><p>清华PyPI镜像：<a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></p><p>阿里云 PyPI 镜像： <a href="https://mirrors.aliyun.com/pypi/simple/">https://mirrors.aliyun.com/pypi/simple/</a></p><p>豆瓣 PyPI 镜像： <a href="https://pypi.douban.com/simple/">https://pypi.douban.com/simple/</a></p><p>腾讯云 PyPI 镜像： <a href="https://mirrors.cloud.tencent.com/pypi/simple/">https://mirrors.cloud.tencent.com/pypi/simple/</a></p><ol start="2"><li><strong>安装包时指定这些软件源</strong>：</li></ol><p><code>pip install -i &lt;software-source-url&gt; &lt;package-name&gt;</code><br>请将 <software-source-url> 替换为您想要使用的软件源的 URL 地址，<package-name> 替换为您要安装的包的名称。例如，要使用阿里云 PyPI 镜像来安装 requests 包，您可以执行以下命令：</p><p><code>pip install -i https://mirrors.aliyun.com/pypi/simple/ requests</code><br>这将使用阿里云 PyPI 镜像源来查找和安装 requests 包。</p><ol start="3"><li><strong>查看 pip 的默认源列表及其配置</strong>：</li></ol><p><code>pip config list</code><br>这将列出所有 pip 配置，包括默认源、软件源、日志设置等。默认源的配置名称为 global.index-url，如果您已经设置了默认源，它将显示在该列表中。</p><p>如果您只想查看默认源的配置，请使用以下命令：</p><p><code>pip config get global.index-url</code><br>这将输出当前默认源的 URL 地址。如果您没有设置默认源，则会显示一个空行。</p><ol start="4"><li><strong>删除默认源的配置</strong>：</li></ol><p><code>pip config unset global.index-url</code><br>这将从 pip 配置中删除默认源的配置。请注意，这不会删除任何已经安装的软件包，但是如果您尝试安装新的包，则 pip 将从默认源中查找该包。如果默认源的配置已经被删除，则 pip 将会从官方源中查找该包。</p><h2 id="Gitpod"><a href="#Gitpod" class="headerlink" title="Gitpod"></a>Gitpod</h2><p>开启快捷方式：<a href="https://gitpod.io/#/github.com/">https://gitpod.io/#/github.com/</a>~</p><h2 id="外刊阅读"><a href="#外刊阅读" class="headerlink" title="外刊阅读"></a>外刊阅读</h2><p>外刊下载地址：<a href="https://newstandshare.azurewebsites.net/">https://newstandshare.azurewebsites.net/</a></p><p>拆分PDF:<a href="https://www.ilovepdf.com/zh-cn/split_pdf">https://www.ilovepdf.com/zh-cn/split_pdf</a></p><p>Google 翻译(文件不可大于10MB)：<a href="https://translate.google.com/?hl=zh-CN&amp;sl=auto&amp;tl=zh-CN&amp;op=docs">https://translate.google.com/?hl=zh-CN&amp;sl=auto&amp;tl=zh-CN&amp;op=docs</a> </p><h2 id="Cmd-or-Powershell管理员权限"><a href="#Cmd-or-Powershell管理员权限" class="headerlink" title="Cmd or Powershell管理员权限"></a>Cmd or Powershell管理员权限</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">##PowerShell</span><br><span class="line">start-process powershell -Verb runAs</span><br><span class="line">##cmd</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;pycharm常用快捷键&quot;&gt;&lt;a href=&quot;#pycharm常用快捷键&quot; class=&quot;headerlink&quot; title=&quot;pycharm常用快捷键&quot;&gt;&lt;/a&gt;pycharm常用快捷键&lt;/h2&gt;&lt;p&gt;常用的PyCharm快捷键：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Al</summary>
      
    
    
    
    <category term="知识总结" scheme="http://example.com/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="实用小知识" scheme="http://example.com/tags/%E5%AE%9E%E7%94%A8%E5%B0%8F%E7%9F%A5%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>pytorch_GPU环境搭建</title>
    <link href="http://example.com/2023/03/20/pytorch-GPU%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    <id>http://example.com/2023/03/20/pytorch-GPU%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</id>
    <published>2023-03-20T08:41:36.000Z</published>
    <updated>2023-03-20T09:08:58.673Z</updated>
    
    <content type="html"><![CDATA[<h2 id="总括"><a href="#总括" class="headerlink" title="总括"></a>总括</h2><p><em><strong>总体过程是通过设备管理器查看显卡型号，去<a href="https://www.nvidia.cn/geforce/drivers/">NVIDIA GeForce 驱动程序 - N 卡驱动 | NVIDIA</a>下载相应显卡驱动，<code>nvidia-smi</code>查看CUDA最高可安装版本，安装对应CUDA和CUDNN(下文有网址)，一般会再安装Anaconda用于环境管理（记得安装时勾选添加环境变量），创建pytorch环境（注意python版本），激活环境在其中安装相应的torch版本，最后验证是否成功</strong></em></p><h2 id="官网安装"><a href="#官网安装" class="headerlink" title="官网安装"></a>官网安装</h2><p>直接去<a href="https://pytorch.org/get-started/previous-versions/">pytorch官网</a><code>previous Pytorch Versions</code>里面已经标注好<code>pytorch</code>以及对应的<code>cuda</code>版本，最新版本首页就是。</p><img src="/2023/03/20/pytorch-GPU%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/%E5%AE%98%E7%BD%91.png" class=""><h2 id="更换国内源-x3D-x3D-一定要删掉defaults-x3D-x3D"><a href="#更换国内源-x3D-x3D-一定要删掉defaults-x3D-x3D" class="headerlink" title="更换国内源 &#x3D;&#x3D;一定要删掉defaults&#x3D;&#x3D;"></a>更换国内源 &#x3D;&#x3D;一定要删掉defaults&#x3D;&#x3D;</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">windows下：</span><br><span class="line"></span><br><span class="line">清华源</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge </span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/</span><br><span class="line"></span><br><span class="line"># 设置搜索时显示通道地址</span><br><span class="line">conda config --set show_channel_urls yes</span><br><span class="line">pytorch配置</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</span><br><span class="line"></span><br><span class="line">中科大源</span><br><span class="line">conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/</span><br><span class="line">conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/</span><br><span class="line">conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/msys2/</span><br><span class="line">conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/bioconda/</span><br><span class="line">conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/menpo/</span><br><span class="line">conda config --set show_channel_urls yes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">linux下：</span><br><span class="line">将以上配置文件写在~/.condarc中</span><br><span class="line">vim ~/.condarc</span><br><span class="line"></span><br><span class="line">channels:</span><br><span class="line">  - https://mirrors.ustc.edu.cn/anaconda/pkgs/main/</span><br><span class="line">  - https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">  - defaults</span><br><span class="line">show_channel_urls: true</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="CUDA与CUDnn安装全过程（多版本）"><a href="#CUDA与CUDnn安装全过程（多版本）" class="headerlink" title="CUDA与CUDnn安装全过程（多版本）"></a>CUDA与CUDnn安装全过程（多版本）</h2><p>CUDA安装链接：<a href="https://developer.nvidia.com/cuda-toolkit-archive">https://developer.nvidia.com/cuda-toolkit-archive</a></p><p>多版本安装时需注意，如果安装的版本比之前的都要高（比如电脑已经有了10.2，现在要装11.3），那么就需要勾选安装全部，反之只需要勾选安装CUDA的那个选项就好。</p><p>安装过程一共涉及到两次安装路径的选择，第一次选择默认（这样不用自己手动添加环境变量，似乎更改后系统仍会自行改回），第二次可以任意更改为自己方便的路径。</p><p>CUDnn安装链接：<a href="https://developer.nvidia.com/rdp/cudnn-download">https://developer.nvidia.com/rdp/cudnn-download</a></p><p>这里面有<code>bin</code> <code>include</code> <code>lib</code>三个文件夹，将对应的文件里的内容复制到你第二次填写安装路径，对应的文件就好。（比如我第二次选择CUDA的安装路径是F:\CUDA10.2,那么我就需要将CUDnn里的<code>bin</code>等文件复制到F:\CUDA10.2\bin中）</p><p>&#x3D;&#x3D;检测安装是否成功&#x3D;&#x3D;</p><img src="/2023/03/20/pytorch-GPU%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/%E5%AE%89%E8%A3%85%E6%88%90%E5%8A%9F.png" class=""><p>&#x3D;&#x3D;不同版本CUDA的切换&#x3D;&#x3D; </p><p>只需要更改环境变量中PATH的上下位置，所需CUDA版本的位置在上，则系统就会调用该版本，就实现了版本的切换。</p><img src="/2023/03/20/pytorch-GPU%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/%E5%88%87%E6%8D%A2.png" class=""><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">##验证是否成功</span><br><span class="line">import torch</span><br><span class="line">print(torch.__version__)                  #torch版本</span><br><span class="line">print(torch.cuda.is_available())          #cuda是否有用</span><br><span class="line">print(torch.backends.cudnn.is_available())#cudnn是否有用</span><br><span class="line">print(torch.cuda_version)                 #当前cuda版本</span><br><span class="line">print(torch.backends.cudnn.version())     #当前cudnn版本</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;总括&quot;&gt;&lt;a href=&quot;#总括&quot; class=&quot;headerlink&quot; title=&quot;总括&quot;&gt;&lt;/a&gt;总括&lt;/h2&gt;&lt;p&gt;&lt;em&gt;&lt;strong&gt;总体过程是通过设备管理器查看显卡型号，去&lt;a href=&quot;https://www.nvidia.cn/geforce</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="pytorch" scheme="http://example.com/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>CUDA与CUDnn安装全过程（多版本）</title>
    <link href="http://example.com/2023/03/02/CUDA%E4%B8%8ECUDnn%E5%AE%89%E8%A3%85%E5%85%A8%E8%BF%87%E7%A8%8B%EF%BC%88%E5%A4%9A%E7%89%88%E6%9C%AC%EF%BC%89/"/>
    <id>http://example.com/2023/03/02/CUDA%E4%B8%8ECUDnn%E5%AE%89%E8%A3%85%E5%85%A8%E8%BF%87%E7%A8%8B%EF%BC%88%E5%A4%9A%E7%89%88%E6%9C%AC%EF%BC%89/</id>
    <published>2023-03-02T02:54:33.000Z</published>
    <updated>2023-03-02T03:04:30.124Z</updated>
    
    <content type="html"><![CDATA[<h2 id="CUDA与CUDnn基本介绍"><a href="#CUDA与CUDnn基本介绍" class="headerlink" title="CUDA与CUDnn基本介绍"></a>CUDA与CUDnn基本介绍</h2><h3 id="什么是CUDA"><a href="#什么是CUDA" class="headerlink" title="什么是CUDA"></a>什么是CUDA</h3><p>CUDA(ComputeUnified Device Architecture)，是显卡厂商NVIDIA推出的运算平台。 CUDA是一种由NVIDIA推出的通用并行计算架构，该架构使GPU能够解决复杂的计算问题。</p><h3 id="什么是CUDNN"><a href="#什么是CUDNN" class="headerlink" title="什么是CUDNN"></a>什么是CUDNN</h3><p>NVIDIA cuDNN是用于深度神经网络的GPU加速库。它强调性能、易用性和低内存开销。NVIDIA cuDNN可以集成到更高级别的机器学习框架中，如谷歌的Tensorflow、加州大学伯克利分校的流行caffe软件。简单的插入式设计可以让开发人员专注于设计和实现神经网络模型，而不是简单调整性能，同时还可以在GPU上实现高性能现代并行计算。</p><h3 id="CUDA与CUDNN的关系"><a href="#CUDA与CUDNN的关系" class="headerlink" title="CUDA与CUDNN的关系"></a>CUDA与CUDNN的关系</h3><p>CUDA看作是一个工作台，上面配有很多工具，如锤子、螺丝刀等。cuDNN是基于CUDA的深度学习GPU加速库，有了它才能在GPU上完成深度学习的计算。它就相当于工作的工具，比如它就是个扳手。但是CUDA这个工作台买来的时候，并没有送扳手。想要在CUDA上运行深度神经网络，就要安装cuDNN，就像你想要拧个螺帽就要把扳手买回来。这样才能使GPU进行深度神经网络的工作，工作速度相较CPU快很多。</p><h2 id="CUDA与CUDnn安装全过程（多版本）"><a href="#CUDA与CUDnn安装全过程（多版本）" class="headerlink" title="CUDA与CUDnn安装全过程（多版本）"></a>CUDA与CUDnn安装全过程（多版本）</h2><p>CUDA安装链接：<a href="https://developer.nvidia.com/cuda-toolkit-archive">https://developer.nvidia.com/cuda-toolkit-archive</a></p><p>多版本安装时需注意，如果安装的版本比之前的都要高（比如电脑已经有了10.2，现在要装11.3），那么就需要勾选安装全部，反之只需要勾选安装CUDA的那个选项就好。</p><p>安装过程一共涉及到两次安装路径的选择，第一次选择默认（这样不用自己手动添加环境变量，似乎更改后系统仍会自行改回），第二次可以任意更改为自己方便的路径。</p><p>CUDnn安装链接：<a href="https://developer.nvidia.com/rdp/cudnn-download">https://developer.nvidia.com/rdp/cudnn-download</a></p><p>这里面有<code>bin</code> <code>include</code> <code>lib</code>三个文件夹，将对应的文件里的内容复制到你第二次填写安装路径，对应的文件就好。（比如我第二次选择CUDA的安装路径是F:\CUDA10.2,那么我就需要将CUDnn里的<code>bin</code>等文件复制到F:\CUDA10.2\bin中）</p><p>检测安装是否成功：</p><img src="/2023/03/02/CUDA%E4%B8%8ECUDnn%E5%AE%89%E8%A3%85%E5%85%A8%E8%BF%87%E7%A8%8B%EF%BC%88%E5%A4%9A%E7%89%88%E6%9C%AC%EF%BC%89/%E5%AE%89%E8%A3%85%E6%88%90%E5%8A%9F.png" class=""><p>不同版本CUDA的切换：</p><p>只需要更改环境变量中PATH的上下位置，所需CUDA版本的位置在上，则系统就会调用该版本，就实现了版本的切换。</p><img src="/2023/03/02/CUDA%E4%B8%8ECUDnn%E5%AE%89%E8%A3%85%E5%85%A8%E8%BF%87%E7%A8%8B%EF%BC%88%E5%A4%9A%E7%89%88%E6%9C%AC%EF%BC%89/%E4%B8%8D%E5%90%8C%E7%89%88%E6%9C%AC%E5%88%87%E6%8D%A2.png" class="">]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;CUDA与CUDnn基本介绍&quot;&gt;&lt;a href=&quot;#CUDA与CUDnn基本介绍&quot; class=&quot;headerlink&quot; title=&quot;CUDA与CUDnn基本介绍&quot;&gt;&lt;/a&gt;CUDA与CUDnn基本介绍&lt;/h2&gt;&lt;h3 id=&quot;什么是CUDA&quot;&gt;&lt;a href=</summary>
      
    
    
    
    <category term="NVIDIA" scheme="http://example.com/categories/NVIDIA/"/>
    
    <category term="通用并行计算架构" scheme="http://example.com/categories/NVIDIA/%E9%80%9A%E7%94%A8%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%9E%B6%E6%9E%84/"/>
    
    <category term="深度神经网络的GPU加速库" scheme="http://example.com/categories/NVIDIA/%E9%80%9A%E7%94%A8%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%9E%B6%E6%9E%84/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84GPU%E5%8A%A0%E9%80%9F%E5%BA%93/"/>
    
    
    <category term="CUDA&amp;CUDnn" scheme="http://example.com/tags/CUDA-CUDnn/"/>
    
  </entry>
  
  <entry>
    <title>《人工智能现代方法》读书笔记</title>
    <link href="http://example.com/2023/02/27/%E3%80%8A%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%8E%B0%E4%BB%A3%E6%96%B9%E6%B3%95%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    <id>http://example.com/2023/02/27/%E3%80%8A%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%8E%B0%E4%BB%A3%E6%96%B9%E6%B3%95%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</id>
    <published>2023-02-27T14:35:27.000Z</published>
    <updated>2023-02-27T15:16:36.424Z</updated>
    
    <content type="html"><![CDATA[<h2 id="第一部分"><a href="#第一部分" class="headerlink" title="第一部分"></a>第一部分</h2><p>人工智能价值大，一万亿美元；影响大，李开复等众人公认；机会多，未来拥有无限可能。</p><p>什么是人工智能？书中有四种方法：</p><ol><li><p>类人类行为（图灵测试）：可以理解为，模仿人体器官运行机制，’嘴巴‘、’大脑‘、’眼睛与耳朵‘、’四肢‘（后两者与前者合称为“完全图灵测试”）</p></li><li><p>类人类思考（基于人类心理行为学研究）：研究的突破口在于利用人类心理与行为的精确对应，使之程序化，从而达到类人类的目的。</p></li><li><p>理性行为（逻辑与概率）：将人类行为分为确定事件和不确定事件，逻辑以处理确定事件，概率以处理不确定事件。</p></li><li><p>理性思考（感知、理解、预测并做出正确的行为）：智能体，标准模型；主流研究方向。</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;第一部分&quot;&gt;&lt;a href=&quot;#第一部分&quot; class=&quot;headerlink&quot; title=&quot;第一部分&quot;&gt;&lt;/a&gt;第一部分&lt;/h2&gt;&lt;p&gt;人工智能价值大，一万亿美元；影响大，李开复等众人公认；机会多，未来拥有无限可能。&lt;/p&gt;
&lt;p&gt;什么是人工智能？书中有四种方</summary>
      
    
    
    
    <category term="读书笔记" scheme="http://example.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="《人工智能现代方法》" scheme="http://example.com/tags/%E3%80%8A%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%8E%B0%E4%BB%A3%E6%96%B9%E6%B3%95%E3%80%8B/"/>
    
  </entry>
  
  <entry>
    <title>报错总汇1</title>
    <link href="http://example.com/2023/02/26/%E6%8A%A5%E9%94%99%E6%80%BB%E6%B1%871/"/>
    <id>http://example.com/2023/02/26/%E6%8A%A5%E9%94%99%E6%80%BB%E6%B1%871/</id>
    <published>2023-02-26T10:31:46.000Z</published>
    <updated>2023-03-23T07:28:19.913Z</updated>
    
    <content type="html"><![CDATA[<h2 id="fatal-Could-not-read-from-remote-repository"><a href="#fatal-Could-not-read-from-remote-repository" class="headerlink" title="fatal: Could not read from remote repository"></a>fatal: Could not read from remote repository</h2><p>问题描述：我在使用命令<code>hexo d -g</code>，通过git上传博客时，发生了标题错误。</p><p>原因分析：没有通过ssh验证，主要原因为长时间未使用，验证代理关闭。</p><p>解决办法：在git bash输入&#x3D;&#x3D;添加&#x3D;&#x3D;<code>ssh-add id_rsa文件路径</code>（路径正斜杠）&#x3D;&#x3D;启动&#x3D;&#x3D;<code>eval ssh-agent -s</code> ，再输入密钥密码完成验证，即可解决报错。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">##自用</span><br><span class="line">ssh-add C:/Users/Hetmyer/.ssh/id_rsa</span><br><span class="line">eval &quot;$(ssh-agent)&quot;#正确输出后就可以尝试连接</span><br><span class="line">大部分网络问题，建议多次尝试</span><br></pre></td></tr></table></figure><img src="/2023/02/26/%E6%8A%A5%E9%94%99%E6%80%BB%E6%B1%871/ssh.png" class=""><img src="/2023/02/26/%E6%8A%A5%E9%94%99%E6%80%BB%E6%B1%871/ssh-agent.png" class=""><img src="/2023/02/26/%E6%8A%A5%E9%94%99%E6%80%BB%E6%B1%871/%E5%AE%8C%E6%95%B4%E6%AD%A5%E9%AA%A4.png" class=""><p>参考链接：<a href="https://stackoverflow.com/questions/13509293/git-fatal-could-not-read-from-remote-repository">https://stackoverflow.com/questions/13509293/git-fatal-could-not-read-from-remote-repository</a></p><h2 id="WARNING-There-was-an-error-checking-the-latest-version-of-pip"><a href="#WARNING-There-was-an-error-checking-the-latest-version-of-pip" class="headerlink" title="WARNING: There was an error checking the latest version of pip."></a>WARNING: There was an error checking the latest version of pip.</h2><p>错误展示：</p><img src="/2023/02/26/%E6%8A%A5%E9%94%99%E6%80%BB%E6%B1%871/PipVPN.png" class=""><p>这里你需要<strong>关闭VPN</strong>（VPN开全局模式也没用），再升级Pip（直接升级Pip汇报一样的错误）</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;fatal-Could-not-read-from-remote-repository&quot;&gt;&lt;a href=&quot;#fatal-Could-not-read-from-remote-repository&quot; class=&quot;headerlink&quot; title=&quot;fatal:</summary>
      
    
    
    
    <category term="报错总汇" scheme="http://example.com/categories/%E6%8A%A5%E9%94%99%E6%80%BB%E6%B1%87/"/>
    
    
    <category term="ssh" scheme="http://example.com/tags/ssh/"/>
    
    <category term="git" scheme="http://example.com/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>Hexo_butterfly博客使用补充</title>
    <link href="http://example.com/2023/02/26/hexo-butterfly%E5%8D%9A%E5%AE%A2%E4%BD%BF%E7%94%A8%E8%A1%A5%E5%85%85/"/>
    <id>http://example.com/2023/02/26/hexo-butterfly%E5%8D%9A%E5%AE%A2%E4%BD%BF%E7%94%A8%E8%A1%A5%E5%85%85/</id>
    <published>2023-02-26T10:13:02.000Z</published>
    <updated>2023-03-02T02:46:00.589Z</updated>
    
    <content type="html"><![CDATA[<h2 id="博客知识补充"><a href="#博客知识补充" class="headerlink" title="博客知识补充"></a>博客知识补充</h2><h3 id="图片引用"><a href="#图片引用" class="headerlink" title="图片引用"></a>图片引用</h3><p>示例：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;% asset_img 示例.png 示例 %&#125; #后一个示例可以不用写</span><br></pre></td></tr></table></figure><p>博客必须写在生成的.md文件中</p><h3 id="新博客生成基本设置"><a href="#新博客生成基本设置" class="headerlink" title="新博客生成基本设置"></a>新博客生成基本设置</h3><p>博文生成设置：</p><img src="/2023/02/26/hexo-butterfly%E5%8D%9A%E5%AE%A2%E4%BD%BF%E7%94%A8%E8%A1%A5%E5%85%85/%E5%8D%9A%E6%96%87%E7%94%9F%E6%88%90%E8%AE%BE%E7%BD%AE.png" class=""><p>新博文头部内容设置：</p><img src="/2023/02/26/hexo-butterfly%E5%8D%9A%E5%AE%A2%E4%BD%BF%E7%94%A8%E8%A1%A5%E5%85%85/%E4%BF%AE%E6%94%B9%E6%96%B0%E5%8D%9A%E5%AE%A2%E5%9F%BA%E6%9C%AC%E8%AE%BE%E7%BD%AE.png" class=""><p>参考网址：<a href="https://blog.csdn.net/zyq55917/article/details/125003333">https://blog.csdn.net/zyq55917/article/details/125003333</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;博客知识补充&quot;&gt;&lt;a href=&quot;#博客知识补充&quot; class=&quot;headerlink&quot; title=&quot;博客知识补充&quot;&gt;&lt;/a&gt;博客知识补充&lt;/h2&gt;&lt;h3 id=&quot;图片引用&quot;&gt;&lt;a href=&quot;#图片引用&quot; class=&quot;headerlink&quot; title=&quot;图</summary>
      
    
    
    
    <category term="web前端" scheme="http://example.com/categories/web%E5%89%8D%E7%AB%AF/"/>
    
    
    <category term="博客" scheme="http://example.com/tags/%E5%8D%9A%E5%AE%A2/"/>
    
  </entry>
  
  <entry>
    <title>AI绘图工具搭建与基本使用</title>
    <link href="http://example.com/2023/02/26/AI%E7%BB%98%E5%9B%BE%E5%B7%A5%E5%85%B7%E6%90%AD%E5%BB%BA%E4%B8%8E%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"/>
    <id>http://example.com/2023/02/26/AI%E7%BB%98%E5%9B%BE%E5%B7%A5%E5%85%B7%E6%90%AD%E5%BB%BA%E4%B8%8E%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/</id>
    <published>2023-02-26T10:04:39.000Z</published>
    <updated>2023-02-27T14:05:24.158Z</updated>
    
    <content type="html"><![CDATA[<h2 id="项目简介"><a href="#项目简介" class="headerlink" title="项目简介"></a>项目简介</h2><p><strong>Stable Diffusion web UI</strong>是基于 Gradio 库的 Stable Diffusion 浏览器界面。</p><p>项目地址：<a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui">https://github.com/AUTOMATIC1111/stable-diffusion-webui</a></p><h2 id="环境配置及注意事项"><a href="#环境配置及注意事项" class="headerlink" title="环境配置及注意事项"></a>环境配置及注意事项</h2><h3 id="readme-md官方安装方式如下"><a href="#readme-md官方安装方式如下" class="headerlink" title="readme.md官方安装方式如下"></a>readme.md官方安装方式如下</h3><h4 id="在-Windows-上自动安装"><a href="#在-Windows-上自动安装" class="headerlink" title="在 Windows 上自动安装"></a>在 Windows 上自动安装</h4><ol><li>安装<a href="https://www.python.org/downloads/windows/">Python 3.10.6</a>，勾选“Add Python to PATH”</li><li>安装<a href="https://git-scm.com/download/win">Git</a>。</li><li>下载 stable-diffusion-webui 存储库，例如通过运行<code>git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git</code>.</li><li><code>webui-user.bat</code>以普通非管理员用户身份从 Windows 资源管理器运行。</li></ol><h4 id="在-Linux-上自动安装"><a href="#在-Linux-上自动安装" class="headerlink" title="在 Linux 上自动安装"></a>在 Linux 上自动安装</h4><ol><li>安装依赖项：</li></ol><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Debian-based:</span><br><span class="line">sudo apt install wget git python3 python3-venv</span><br><span class="line"># Red Hat-based:</span><br><span class="line">sudo dnf install wget git python3</span><br><span class="line"># Arch-based:</span><br><span class="line">sudo pacman -S wget git python3</span><br></pre></td></tr></table></figure><ol><li>要在 中安装<code>/home/$(whoami)/stable-diffusion-webui/</code>，请运行：</li></ol><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bash &lt;(wget -qO- https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh)</span><br></pre></td></tr></table></figure><ol><li>运行<code>webui.sh</code>。</li></ol><p>以上即为官方提供的安装方式，对于有类似安装经验的小伙伴，看到这些已经足够。但是对于“新手”朋友而言，可能在安装过程中就会有很多疑问、遇到各种问题。为了能够一起玩耍共同感受AI魅力，下面我将会以windows系统为例，较为详细地操作一遍，希望能帮到这些朋友。</p><h3 id="较为详细的安装步骤"><a href="#较为详细的安装步骤" class="headerlink" title="较为详细的安装步骤"></a>较为详细的安装步骤</h3><p>我在安装的过程中，尝试过利用已有的Anaconda环境来达到节约储存空间的目的。在过程中，虽然可以使用不是3.10.6版本的python进入到下一步的配置过程，但是提示也说明了，非3.10.6版本的可能不能正常运行。起初，我忽略提示继续安装，然而后续它在我已有torch的情况下，仍然要重新下载torch-1.13.1+cu117。看到这里有些小伙伴可能会想到修改其安装源码来达到我们使用现有环境的目的。不过，我从现实角度出发，这个不过是一个AI工具，我们没必要为了一点储存空间而浪费宝贵的时间，因此我就没有作进一步的探索，而是老老实实地让它自动安装相应版本。以下是我的安装配置过程：</p><p>首先是安装3.10.6版本的python。安装网址：<a href="https://www.python.org/downloads/release/python-3106/">https://www.python.org/downloads/release/python-3106/</a></p><p>这里有两点注意：</p><ol><li>&#x3D;&#x3D;不要下载最新版本的python&#x3D;&#x3D;，因为在后续执行<code>webui-user.bat</code>文件时需要安装可调用GPU的torch，版本为torch-1.13.1+cu117。如果你安装了最新版python，会与该版本的torch发生冲突就无法安装成功。</li><li>在安装python时（双击.exe文件后看到的第一个画面），一定要勾选将python路径添加到环境变量中，不然之后运行<code>webui-user.bat</code>将可能出现无法launch python。如果实在忘了的小伙伴也可以在安装完成后，自己手动添加。方法是先找到你安装python的路径，在路径后加上python.exe，复制，打开设置&gt;系统&gt;系统信息&gt;高级系统设置&gt;环境变量&gt;找到系统变量左侧的Path，选中，再点击新建&gt;将之前复制的路径粘贴进去，然后一路点确定。</li></ol><p>安装后，我们需要按住win+R键，输入cmd打开终端，在输入python或者py，如果出现了python版本信息则证明安装成功。</p><p>其次，我们安装Git。安装网址：<a href="https://git-scm.com/download/win">https://git-scm.com/download/win</a> </p><p>选择自己电脑对应的版本，下载，安装。这里应该没啥问题，就和一般应用程序安装一样。安装好后，我们切换到自己要存放项目的文件夹，鼠标右击，点击<code>Git Bash Here</code>进入Git终端，随后输入：git clone <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui.git">https://github.com/AUTOMATIC1111/stable-diffusion-webui.git</a></p><p>等待克隆完毕。</p><p>最后，我们进入刚刚克隆好的文件，找到<code>wedui-user.bat</code>文件，直接双击运行，它将会自动安装相应的库和文件配置。如果出现了类似“SSLError”问题，你只需要，根据提示“按任意键继续”，退出终端，重新运行<code>wedui-user.bat</code>文件,这一步多是网络问题，需要科学上网并记得设置为全局模式，多尝试几次。或者，根据报错提示，自行下载相应的库、模型。</p><h4 id="“no-xformers”问题解决"><a href="#“no-xformers”问题解决" class="headerlink" title="“no xformers”问题解决"></a>“no xformers”问题解决</h4><p>用编辑器打开<code>webui-user.bat</code>文件，添加如下指令：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">set COMMANDLINE_ARGS=--medvram --reinstall-xformers --xformers</span><br></pre></td></tr></table></figure><p>这条指令就是让我们，再次尝试下载xformers还有相应的模型。如果，还没有解决，我们还是需要多试几次，这主要是网络问题。直到出现本地网址，则说明成功。接下来你可以按住ctrl键，鼠标点击出现的网址，就可以看到AI绘图工具的可视化操作界面了！</p><h2 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h2><p>Web UI界面如图：</p><img src="/2023/02/26/AI%E7%BB%98%E5%9B%BE%E5%B7%A5%E5%85%B7%E6%90%AD%E5%BB%BA%E4%B8%8E%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/%E7%95%8C%E9%9D%A2%E4%BB%8B%E7%BB%8D.png" class="" title="界面介绍"><p>规定在前：✔后数字代表相应功能区，接下来我将会分区介绍。</p><h3 id="基本介绍和使用流程"><a href="#基本介绍和使用流程" class="headerlink" title="基本介绍和使用流程"></a>基本介绍和使用流程</h3><p>首先是在1区选择你下载好的Check Point模型，再到2区填写需要生成图片的文字描述，在4区填写消极的文字描述（可以理解为AI对3区文字描述可能产生误解的部分），再到5区选择生成图片的样式，6区的阈值与5区对应（大则表示“更像”），8区是图片大小，10区是图片数目，9区调节的是图片与文字描述的吻合度（数值越大越符合），11区是种子数（-1代表随机，点一下绿色图标表示固定种子数，这一般用于在同一张图片进行修改），12区是图片生成、中断开关，13区是图片呈现区。</p><h3 id="extra-networks"><a href="#extra-networks" class="headerlink" title="extra networks"></a>extra networks</h3><img src="/2023/02/26/AI%E7%BB%98%E5%9B%BE%E5%B7%A5%E5%85%B7%E6%90%AD%E5%BB%BA%E4%B8%8E%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/extra_networks.png" class=""><p>点击图示图标即可看到，extra networks区，这里可以使你的图片呈现更多种风格的样式。这里就需要小伙伴自己探索啦。</p><h3 id="prompt生成技巧"><a href="#prompt生成技巧" class="headerlink" title="prompt生成技巧"></a>prompt生成技巧</h3><p>这里可以借助ChatGPT，来帮组生成。效果如图：</p><img src="/2023/02/26/AI%E7%BB%98%E5%9B%BE%E5%B7%A5%E5%85%B7%E6%90%AD%E5%BB%BA%E4%B8%8E%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/chatgpt2pic.png" class=""><p>“咒语”：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">下面的prompt是用来指导AI绘画模型创作图像的。它们包含了图像的各种细节，如人物的外观、背景、颜色和光线效果，以及图像的主题和风格。这些prompt的格式经常包含括号内的加权数字，用于指定某些细节的重要性或强调。例如，&quot;(masterpiece:1.5)&quot;表示作品质量是非常重要的，多个括号也有类似作用。此外，如果使用中括号，如&quot;&#123;blue hair:white hair:0.3&#125;&quot;，这代表将蓝发和白发加以融合，蓝发占比为0.3。</span><br><span class="line">以下是用prompt帮助AI模型生成图像的例子：masterpiece,(bestquality),highlydetailed,ultra-detailed,  cold , solo , ( 1girl ) , detailedeyes , shinegoldeneyes ) ( longliverhair ) expressionless , ( long sleeves , puffy sleeves ) ,  ( white wings ) , shinehalo , ( heavymetal : 1 . 2 ) , ( metaljewelry ) ,  cross-lacedfootwear ( chain ) ,  ( Whitedoves : 1 . 2 ) </span><br><span class="line">可以选择的prompt包括：</span><br><span class="line"></span><br><span class="line">颜色</span><br><span class="line">    light（明）</span><br><span class="line">    dark（暗）</span><br><span class="line">    pale（薄）</span><br><span class="line">    deep（濃）</span><br><span class="line">天气 时间</span><br><span class="line">    golden hour lighting  （阳光照明）</span><br><span class="line">    strong rim light      （强边缘光照）</span><br><span class="line">    intense shadows  （强烈的阴影）</span><br><span class="line">    in the rain            （雨）</span><br><span class="line">    rainy days              （雨）</span><br><span class="line">    sunset                  （日落）</span><br><span class="line">    cloudy                   （多云）</span><br><span class="line">建筑物</span><br><span class="line">    in the baroque architecture     （巴洛克建筑 文艺复兴时期意大利的一种装修风格，外形自由，追求动感，喜好富丽）</span><br><span class="line">    in the romanesque architecture streets        （罗马式街道）</span><br><span class="line">    in the palace                                 （宫廷）</span><br><span class="line">    at the castle（城的外观为背景）</span><br><span class="line">    in the castle（城的内部为背景）</span><br><span class="line">    in the street                                   （在街上）</span><br><span class="line">    in the cyberpunk city                       （在赛博朋克城市里）</span><br><span class="line">    rainy night in a cyberpunk city with glowing neon lights  （在雨天的赛博朋克城市，还有霓虹灯）</span><br><span class="line">    at the lighthouse                               （在灯塔周围）</span><br><span class="line">    in misty onsen                                 （温泉）</span><br><span class="line">    by the moon                                     （月亮边上）</span><br><span class="line">    in a bar, in bars                                   （酒吧）</span><br><span class="line">    in a tavern                                        （居酒屋）</span><br><span class="line">    Japanese arch                                  （鳥居）</span><br><span class="line">    in a locker room                                 （在上锁的房间里）</span><br><span class="line">山</span><br><span class="line">    on a hill（山上）</span><br><span class="line">    the top of the hill（山顶）</span><br><span class="line">海</span><br><span class="line">    on the beach       （海滩上）</span><br><span class="line">    over the sea           （海边上）</span><br><span class="line">    beautiful purple sunset at beach  （海边的美丽日落）</span><br><span class="line">    in the ocean           （海中）</span><br><span class="line">    on the ocean          （船上）</span><br><span class="line">仿照例子，并不局限于我给你的单词，给出一套详细描述“从国际空间站，看壮观的、灯火璀璨的地球夜景”的prompt，注意：masterpiece,(bestquality),highlydetailed,ultra-detailed</span><br><span class="line">必须放在前面，直接开始给出prompt不需要用自然语言描述</span><br></pre></td></tr></table></figure><h2 id="参考资料与补充"><a href="#参考资料与补充" class="headerlink" title="参考资料与补充"></a>参考资料与补充</h2><p>模型下载网址:<a href="https://civitai.com/">https://civitai.com/</a></p><img src="/2023/02/26/AI%E7%BB%98%E5%9B%BE%E5%B7%A5%E5%85%B7%E6%90%AD%E5%BB%BA%E4%B8%8E%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/%E5%AF%B9%E5%BA%94%E5%AD%98%E6%94%BE%E7%9B%AE%E5%BD%95.png" class="">]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;项目简介&quot;&gt;&lt;a href=&quot;#项目简介&quot; class=&quot;headerlink&quot; title=&quot;项目简介&quot;&gt;&lt;/a&gt;项目简介&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Stable Diffusion web UI&lt;/strong&gt;是基于 Gradio 库的 Stable D</summary>
      
    
    
    
    <category term="github项目" scheme="http://example.com/categories/github%E9%A1%B9%E7%9B%AE/"/>
    
    
    <category term="stable_diffusion_webui" scheme="http://example.com/tags/stable-diffusion-webui/"/>
    
    <category term="AI绘画" scheme="http://example.com/tags/AI%E7%BB%98%E7%94%BB/"/>
    
  </entry>
  
  <entry>
    <title>科学上网那些事儿</title>
    <link href="http://example.com/2023/02/26/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/"/>
    <id>http://example.com/2023/02/26/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/</id>
    <published>2023-02-26T05:00:07.000Z</published>
    <updated>2023-02-26T06:25:36.617Z</updated>
    
    <content type="html"><![CDATA[<h2 id="V2rayN简介"><a href="#V2rayN简介" class="headerlink" title="V2rayN简介"></a>V2rayN简介</h2><p>V2rayN客户端是一个基于V2ray 内核的windows客户端，它目前支持Xray内核，然后也可以手动更新核心和客户端的版本。下载即用，数据可视化（能看到你访问的网址）、上手也简单。</p><p>下载地址：<a href="https://github.com/2dust/v2rayN/releases/">https://github.com/2dust/v2rayN/releases/</a></p><h2 id="基本使用方法"><a href="#基本使用方法" class="headerlink" title="基本使用方法"></a>基本使用方法</h2><h3 id="启动V2rayN"><a href="#启动V2rayN" class="headerlink" title="启动V2rayN"></a>启动V2rayN</h3><p>下载解压安装后，双击运行V2rayN.exe</p><img src="/2023/02/26/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/V2rayN.exe%E8%BF%90%E8%A1%8C.png" class="" title="V2rayN.exe运行"><p>若没有弹出主界面，可以通过点击任务栏“反V”中的V2rayN图标，跳出主界面。如图示：</p><img src="/2023/02/26/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/V2rayN%E5%9B%BE%E6%A0%87.png" class=""><h3 id="三种导入节点的方式"><a href="#三种导入节点的方式" class="headerlink" title="三种导入节点的方式"></a>三种导入节点的方式</h3><ol><li>复制节点，点击一下主界面，ctrl + V粘贴</li><li>点击订阅设置，添加名字和url，并启用。</li><li>如果是二维码，我们就需要右击任务栏“反V”中的V2rayN图标，你就可以看到“扫描屏幕中的二维码”，完成导入</li></ol><h3 id="运行节点"><a href="#运行节点" class="headerlink" title="运行节点"></a>运行节点</h3><p>直接选中你想要的节点，再回车。</p><h3 id="其他细节"><a href="#其他细节" class="headerlink" title="其他细节"></a>其他细节</h3><p>其他类似设置全局、自动配置系统代理，你可以在下面找到。</p><img src="/2023/02/26/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%90%86.png" class="" title="系统代理"><p>如果是新手，只是想简单使用，直接选中“自动配置系统代理”，然后运行节点即可。</p><h2 id="常用快捷键"><a href="#常用快捷键" class="headerlink" title="常用快捷键"></a>常用快捷键</h2><p>ctrl + A 全选</p><p>ctrl + R 测连接速度延迟(ms)</p><p>ctrl + T 测下载速度（MB&#x2F;s）</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;V2rayN简介&quot;&gt;&lt;a href=&quot;#V2rayN简介&quot; class=&quot;headerlink&quot; title=&quot;V2rayN简介&quot;&gt;&lt;/a&gt;V2rayN简介&lt;/h2&gt;&lt;p&gt;V2rayN客户端是一个基于V2ray 内核的windows客户端，它目前支持Xray内核，</summary>
      
    
    
    
    <category term="科学上网" scheme="http://example.com/categories/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"/>
    
    
    <category term="V2ray" scheme="http://example.com/tags/V2ray/"/>
    
    <category term="VPN" scheme="http://example.com/tags/VPN/"/>
    
  </entry>
  
  <entry>
    <title>Hexo_github_butterfly 博客搭建</title>
    <link href="http://example.com/2023/02/03/hexo-github-butterfly-%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    <id>http://example.com/2023/02/03/hexo-github-butterfly-%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/</id>
    <published>2023-02-02T20:56:08.000Z</published>
    <updated>2023-02-26T10:45:31.946Z</updated>
    
    <content type="html"><![CDATA[<h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><p>1.Node.js<br>因为Hexo是一个基于Node.js的静态博客框架，因此需要先安装Node.js环境，<code>node.js</code>多版本下载地址：<a href="https://nodejs.org/en/download/releases/">https://nodejs.org/en/download/releases/</a></p><p>2.Git<br>此处为Windows平台下的下载地址：<a href="https://git-scm.com/download/win">Git</a><br>或者可以选择直接下载:<a href="https://desktop.github.com/">GitHub Desktop</a><br>Mac及其他操作系统请参考Hexo官方提供的下载链接。</p><h2 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h2><p>建议win用户在Git Bash中执行命令<br>由于安装Hexo要用到npm，但是有时候速度很慢，如果速度过慢我们可以使用淘宝镜像</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ npm install -g cnpm --registry=https://registry.npm.taobao.org</span><br></pre></td></tr></table></figure><p>安装淘宝源之后只需要npm换成cnpm就行了。如<code>$ cnpm install hexo-cli -g</code><br>当然，如果你使用npm速度可以的话，那么安装淘宝源这一步你可以忽略</p><p>完成以上环境配置之后，通过下面的命令安装Hexo</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure><p>当出现<code>Start blogging with Hexo !</code>表示Hexo安装成功</p><h2 id="建站"><a href="#建站" class="headerlink" title="建站"></a>建站</h2><p>安装完成之后，选择一个目录作为建站所需文件的存放路径，如我选择G:\workspace\myblog，执行以下命令完成hexo的初始化</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo init G:\workspace\myblog</span><br></pre></td></tr></table></figure><p>然后命令行进入该目录</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd G:\workspace\myblog</span><br></pre></td></tr></table></figure><p>执行下面的命令，系统会可以根据package.json文件中dependencies的配置安装所有依赖包</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm install</span><br></pre></td></tr></table></figure><p>新建完成之后，根目录文件夹下各个目录的含义，可以参考Hexo官网的解释：<a href="https://hexo.io/zh-cn/docs/setup.html">目录信息</a></p><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><p>在建站工具的根目录（如上G:\workspace\myblog）下通过以下命令启动服务器，之后访问网址 <a href="http://localhost:4000/">http://localhost:4000/</a> 即可看到我们刚刚建立的博客，Hexo会默认生成一个Hello World的博文</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo s</span><br></pre></td></tr></table></figure><p>hexo s是hexo server的简写，效果是一样的。这样我们就已经可以在本地浏览我们自己的博客了。以后每次对博客进行修改，都可以先通过这种方式进行本地的预览，满意之后再部署到GitHub Pages上</p><h2 id="部署到GitHub-ssh部分"><a href="#部署到GitHub-ssh部分" class="headerlink" title="部署到GitHub(ssh部分)"></a>部署到GitHub(ssh部分)</h2><p>&#x3D;&#x3D;可以直接使用<code>Gitkraken</code>应用程序完成搭建和部署&#x3D;&#x3D;，下载地址：<a href="https://www.gitkraken.com/">https://www.gitkraken.com/</a></p><p>基本使用教程推荐：<a href="https://www.youtube.com/watch?v=q4CQBuZ4IGo">https://www.youtube.com/watch?v=q4CQBuZ4IGo</a></p><p>如下是手动配置：</p><ul><li>首先在你的GitHub上新建一个Repository，仓库名的固定写法为 your_user_name.github.io<br>Repository新建完成之后，点击界面右侧的Settings，你将会打开这个库的setting页面，向下拖动，直到看见GitHub Pages 。点击Automatic page generator，Github将会自动替你创建出一个gh-pages</li><li>配置SSH-Key：参考官网资料<a href="https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent">https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent</a></li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">概括步骤</span><br><span class="line">打开git bash</span><br><span class="line"></span><br><span class="line">##生成ssh密钥</span><br><span class="line">ssh-keygen -t ed25519 -C &quot;your_email@example.com&quot;（若不支持ed25519则：ssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com&quot;</span><br><span class="line">上述命令输入后，会经历确认密钥文件保存地址、输入密钥、再次输入密码</span><br><span class="line"></span><br><span class="line">##将ssh密钥添加到ssh-agent</span><br><span class="line">1.确保ssh-agent运行</span><br><span class="line">输入和返回类似于</span><br><span class="line">$ eval &quot;$(ssh-agent -s)&quot;</span><br><span class="line">&gt; Agent pid 59566</span><br><span class="line">2.将ssh密钥添加到ssh-agen</span><br><span class="line">ssh-add ~/.ssh/yourname</span><br><span class="line">3.将.pub文件内容加入github&gt;setting&gt;ssh&gt;new ssh&gt;add</span><br><span class="line"></span><br><span class="line">##为硬件安全密钥生成新的ssh密钥</span><br><span class="line">生成密钥、将.pub文件内容加入github&gt;setting&gt;ssh&gt;new ssh&gt;add</span><br></pre></td></tr></table></figure><ul><li>修改根目录的网站配置文件_config.yml，搜索deploy字段，修改成如下所示的格式</li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Deployment</span><br><span class="line">## Docs: https://hexo.io/docs/one-command-deployment</span><br><span class="line">deploy:</span><br><span class="line">  type: &#x27;git&#x27;</span><br><span class="line">  repo: git@github.com:EurekaCheng/EurekaCheng.github.io.git</span><br><span class="line">  branch: main</span><br></pre></td></tr></table></figure><p>其中，repo是我们刚刚建立的远程仓库，换成你自己的id，同时因为刚才配置了SSH-Key，所以必须是SSH形式的URL&#x3D;&#x3D;值得注意的是&#x3D;&#x3D;每一个后面都必须有一个空格，否则会引起错误</p><ul><li>安装Git包，执行以下命令</li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure><ul><li>部署到GitHub上，执行以下的命令</li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo d</span><br></pre></td></tr></table></figure><p>hexo d是hexo deploy的简写，你也可以执行后者，效果是一样的。有时候如果部署不成功的话可以试试<code>hexo d -g</code>命令。或者可以用先<code>hexo g</code>后<code>hexo d</code>的命令组合。以后每次在本地编辑完成之后直接使用<code>hexo d</code>或者<code>hexo d -g</code>就可以部署到Github了</p><p>现在我们可以通过访问<code> https://yourname.github.io/</code>来访问我们自己的博客了！至此，我们的博客已经基本建立完成，下面要说说怎么使用。</p><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>Hexo常用命令</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo generate (hexo g) 生成静态文件，会在当前目录下生成一个新的叫做public的文件夹</span><br><span class="line">hexo server (hexo s) 启动本地web服务，用于博客的预览</span><br><span class="line">hexo deploy (hexo d) 部署播客到远端（比如github, heroku等平台）</span><br></pre></td></tr></table></figure><p>先说说hexo命令常用简写和常用组合</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ hexo n == hexo new</span><br><span class="line">$ hexo g == hexo generate</span><br><span class="line">$ hexo s == hexo server</span><br><span class="line">$ hexo d == hexo deploy</span><br></pre></td></tr></table></figure><p>常用组合</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ hexo d -g #生成部署</span><br><span class="line">$ hexo s -g #生成预览</span><br></pre></td></tr></table></figure><p>新建一篇博文可通过以下的命令</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo new &quot;name&quot;</span><br></pre></td></tr></table></figure><p>其中name为博文的名字，建立完成之后，可以在.&#x2F;source&#x2F;_posts文件夹下发现我们刚刚建立name.md文件。使用你熟悉的编辑器打开，便可以进行博文的撰写。博文支持MarkDown语法的编写，下面是一个示例文件的内容</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: name</span><br><span class="line">date: 2016-04-06 10:34:21</span><br><span class="line">tags:</span><br><span class="line">- 日志</span><br><span class="line">categories:</span><br><span class="line">- 日志</span><br><span class="line">---</span><br><span class="line">博文内容</span><br></pre></td></tr></table></figure><p>博文写好之后，在每次发布之前，我们要先将写好的博客生成静态文件，执行以下命令</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo generate</span><br></pre></td></tr></table></figure><p>之后生成的文件会放在.&#x2F;public目录下，这便是我们将要部署到GitHub上的全部内容</p><p>静态文件生成之后，便可以部署到GitHub</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo deploy</span><br></pre></td></tr></table></figure><p>再重新打开我们的博客 网址已经可以看到刚刚新加入的博文.</p><h2 id="主题"><a href="#主题" class="headerlink" title="主题"></a>主题</h2><p>Hexo提供了丰富的主题可供我们选择和使用.&#x2F;themes目录下存放主题。刚才默认生成的博客用的就是默认的主题landscape。这里有在GitHub上Hexo所有的主题，可以访问<a href="https://github.com/hexojs/hexo/wiki/Themes">https://github.com/hexojs/hexo/wiki/Themes</a></p><ol><li>安装主题的命令</li></ol><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone &lt;repository&gt; themes/&lt;theme-name&gt;</span><br></pre></td></tr></table></figure><ol start="2"><li>打开 _config.yml文件，修改theme关键字段，改为刚才下载的 theme-name.我自己用的主题是Butterfly,如果你想使用butterfly主题请参考以下步骤</li></ol><h2 id="Butterfly主题配置"><a href="#Butterfly主题配置" class="headerlink" title="Butterfly主题配置"></a>Butterfly主题配置</h2><p>首先cd到博客根目录，然后执行</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/jerryc127/hexo-theme-butterfly</span><br></pre></td></tr></table></figure><p>然后修改配置文件<br>修改站点配置文件_config.yml，找到以下部分</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Extensions</span><br><span class="line">## Plugins: http://hexo.io/plugins/</span><br><span class="line">## Themes: http://hexo.io/themes/</span><br><span class="line">theme: landscape</span><br></pre></td></tr></table></figure><p>修改为：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Extensions</span><br><span class="line">## Plugins: https://hexo.io/plugins/</span><br><span class="line">## Themes: https://hexo.io/themes/</span><br><span class="line">theme: Butterfly</span><br></pre></td></tr></table></figure><p>至此，Butterfly主题就安装好了，非常方便，在Hexo中切换主题只需修改站点配置文件中theme属性来配置，想换就换。<br>进一步地美化Butterfly博客请参考链接：<a href="https://www.little-demon.cn/archives/16/">https://www.little-demon.cn/archives/16/</a></p><p>以上基本就完成了博客的搭建和配置，感谢你的阅读，希望对你自己博客的创建有所帮助！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;环境配置&quot;&gt;&lt;a href=&quot;#环境配置&quot; class=&quot;headerlink&quot; title=&quot;环境配置&quot;&gt;&lt;/a&gt;环境配置&lt;/h2&gt;&lt;p&gt;1.Node.js&lt;br&gt;因为Hexo是一个基于Node.js的静态博客框架，因此需要先安装Node.js环境，&lt;code&gt;</summary>
      
    
    
    
    <category term="web前端" scheme="http://example.com/categories/web%E5%89%8D%E7%AB%AF/"/>
    
    
    <category term="博客" scheme="http://example.com/tags/%E5%8D%9A%E5%AE%A2/"/>
    
    <category term="ssh" scheme="http://example.com/tags/ssh/"/>
    
    <category term="github" scheme="http://example.com/tags/github/"/>
    
  </entry>
  
</feed>
